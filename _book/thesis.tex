% This is the Reed College LaTeX thesis template. Most of the work
% for the document class was done by Sam Noble (SN), as well as this
% template. Later comments etc. by Ben Salzberg (BTS). Additional
% restructuring and APA support by Jess Youngberg (JY).
% Your comments and suggestions are more than welcome; please email
% them to cus@reed.edu
%
% See http://web.reed.edu/cis/help/latex.html for help. There are a
% great bunch of help pages there, with notes on
% getting started, bibtex, etc. Go there and read it if you're not
% already familiar with LaTeX.
%
% Any line that starts with a percent symbol is a comment.
% They won't show up in the document, and are useful for notes
% to yourself and explaining commands.
% Commenting also removes a line from the document;
% very handy for troubleshooting problems. -BTS

% As far as I know, this follows the requirements laid out in
% the 2002-2003 Senior Handbook. Ask a librarian to check the
% document before binding. -SN

%%
%% Preamble
%%
% \documentclass{<something>} must begin each LaTeX document
\documentclass[12pt,twoside]{reedthesis}
% Packages are extensions to the basic LaTeX functions. Whatever you
% want to typeset, there is probably a package out there for it.
% Chemistry (chemtex), screenplays, you name it.
% Check out CTAN to see: http://www.ctan.org/
%%
\usepackage{graphicx,latexsym}
\usepackage{amsmath}
\usepackage{amssymb,amsthm}
\usepackage{longtable,booktabs,setspace}
\usepackage{chemarr} %% Useful for one reaction arrow, useless if you're not a chem major
\usepackage[hyphens]{url}
% Added by CII
\usepackage[hidelinks]{hyperref}
\usepackage{lmodern}
\usepackage{float}
\floatplacement{figure}{H}
% End of CII addition
\usepackage{rotating}

% Next line commented out by CII
%%% \usepackage{natbib}
% Comment out the natbib line above and uncomment the following two lines to use the new
% biblatex-chicago style, for Chicago A. Also make some changes at the end where the
% bibliography is included.
%\usepackage{biblatex-chicago}
%\bibliography{thesis}


% Added by CII (Thanks, Hadley!)
% Use ref for internal links
\renewcommand{\hyperref}[2][???]{\autoref{#1}}
\def\chapterautorefname{Chapter}
\def\sectionautorefname{Section}
\def\subsectionautorefname{Subsection}
% End of CII addition

% Added by CII
\usepackage{caption}
\captionsetup{width=5in}
% End of CII addition

% \usepackage{times} % other fonts are available like times, bookman, charter, palatino


% To pass between YAML and LaTeX the dollar signs are added by CII
\title{\textbf{\Huge{On the Numerical simulation of the \\[20pt] Heston model}}}
\author{Fernando O. Teixeira}
% The month and year that you submit your FINAL draft TO THE LIBRARY (May or December)
\date{September 25, 2017}
\division{Applied Mathematics}
\advisor{Hugo Alexander de la Cruz Cancino}
%If you have two advisors for some reason, you can use the following
% Uncommented out by CII
% End of CII addition

%%% Remember to use the correct department!
\department{Mathematics}
% if you're writing a thesis in an interdisciplinary major,
% uncomment the line below and change the text as appropriate.
% check the Senior Handbook if unsure.
%\thedivisionof{The Established Interdisciplinary Committee for}
% if you want the approval page to say "Approved for the Committee",
% uncomment the next line
%\approvedforthe{Committee}

% Added by CII
%%% Copied from knitr
%% maxwidth is the original width if it's less than linewidth
%% otherwise use linewidth (to make sure the graphics do not exceed the margin)
\makeatletter
\def\maxwidth{ %
  \ifdim\Gin@nat@width>\linewidth
    \linewidth
  \else
    \Gin@nat@width
  \fi
}
\makeatother

\renewcommand{\contentsname}{Table of Contents}
% End of CII addition

\setlength{\parskip}{0pt}

% Added by CII

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

\Acknowledgements{
I would first like express my sincere appreciaton to my advisor Hugo de
la Cruz for his help. Also, professor Yuri guidance, steering me to the
correct path and help when I had questions. Finally, I would like to
thank my family and friends who supported me through this path.
\textbf{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ }
You get pseudo-order when you seek order; you only get a measure of
order and control when you embrace randomness. --- Nassim Nicholas Taleb
}

\Dedication{

}

\Preface{

}

\Abstract{
In this thesis we revisit numerical methods for the simulation of the
Heston model's European call. Specifically, we study the Euler, the
Kahl-Jackel an two versions of the exact algorithm schemes. To perform
this task, firstly we present a literature review which brings
stochastic calculus, the Black-Scholes (BS) model and its limitations,
the stochastic volatility methods and why they resolve the issues of the
BS model, and the peculiarities of the numerical methods - convergence,
discretization and stability. We provide recommendations when we
acknowledge that the reader might need more specifics and might need to
dive deeper into a given topic. We introduce the methods aforementioned
providing all our implementations in R language within a package.
\newline \newline \textbf{Keywords:} Heston, Stochastic, Volatility,
Black-Scholes, European call, R
}

	\usepackage{mathtools}
	\usepackage{cancel}
	\graphicspath{ {figure/} }
	\usepackage{enumitem}
	\usepackage{caption}
	\usepackage{graphicx}
% End of CII addition
%%
%% End Preamble
%%
%

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}{Lemma}[section]
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{corollary}{Corollary}[section]
\newtheorem{proposition}{Proposition}[section]
\theoremstyle{definition}
\newtheorem{example}{Example}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\let\BeginKnitrBlock\begin \let\EndKnitrBlock\end
\begin{document}

% Everything below added by CII
      \maketitle
  
  \frontmatter % this stuff will be roman-numbered
  \pagestyle{empty} % this removes page numbers from the frontmatter
      \begin{acknowledgements}
      I would first like express my sincere appreciaton to my advisor Hugo de
      la Cruz for his help. Also, professor Yuri guidance, steering me to the
      correct path and help when I had questions. Finally, I would like to
      thank my family and friends who supported me through this path.
      \textbf{\\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ \\ }
      You get pseudo-order when you seek order; you only get a measure of
      order and control when you embrace randomness. --- Nassim Nicholas Taleb
    \end{acknowledgements}
  
      \hypersetup{linkcolor=black}
    \setcounter{tocdepth}{2}
    \tableofcontents
  
      \listoftables
  
      \listoffigures
      \begin{abstract}
      In this thesis we revisit numerical methods for the simulation of the
      Heston model's European call. Specifically, we study the Euler, the
      Kahl-Jackel an two versions of the exact algorithm schemes. To perform
      this task, firstly we present a literature review which brings
      stochastic calculus, the Black-Scholes (BS) model and its limitations,
      the stochastic volatility methods and why they resolve the issues of the
      BS model, and the peculiarities of the numerical methods - convergence,
      discretization and stability. We provide recommendations when we
      acknowledge that the reader might need more specifics and might need to
      dive deeper into a given topic. We introduce the methods aforementioned
      providing all our implementations in R language within a package.
      \newline \newline \textbf{Keywords:} Heston, Stochastic, Volatility,
      Black-Scholes, European call, R
    \end{abstract}
  
  \mainmatter % here the regular arabic numbering starts
  \pagestyle{fancyplain} % turns page numbering back on

  \chapter{\texorpdfstring{altadvisor: `Your Other
  Advisor'}{altadvisor: Your Other Advisor}}\label{altadvisor-your-other-advisor}
  
  \chapter{Theoretical Framework}\label{lt-review}
  
  This chapter presents the concepts of stochastic calculus, from the
  historic conception of how it first arose through the basic principles
  and applications in finance. We address with more care the classical
  Black-Scholes model and its limitations and the Heston model. This model
  is also well known, it brings the concept of stochastic volatility in
  it, which presents results closer to reality.
  
  \section{Stochastic Calculus}\label{stochastic-calculus}
  
  Stochastic calculus arises from stochastic processes and allows the
  creation of a theory of integration where both the integrand and
  integrator terms are stochastic processes. Stochastic calculus was
  created by the Japanese mathematician Kiyosi It√¥ in the 1940s and 1950s
  and is used for modeling financial options and in another wide variety
  of fields {[}1{]}. In this chapter we present the historical contexts in
  which the tools and models are used, but our focus is introducing the
  concepts and notations that will be further used in our work.
  
  \subsection{Stochastic differential equation -
  SDE}\label{stochastic-differential-equation---sde}
  
  At first, before introducing stochastic differential equation, it is
  helpful to start with ordinary differential equation. Let \(x_t\) denote
  an asset at time \(t\) so that the change in the asset at time \(t\) is
  given by the following deterministic differential equation:
  \begin{align}
  dx_t &= f(t, x_t)dt \\
  x(0) &= x_0 \nonumber
  \end{align}
  We now add a ``noise'' to this equation:
  \begin{align} \label{eq:sde1}
  dx_t &= \overbrace{\underbrace{f(t, x_t)}_\text{drift}dt}^\text{deterministic} + \overbrace{\underbrace{g(t, x_t)}_\text{diffusion}dW_t}^\text{random shock} \\
  x(0) &= x_0 \nonumber
  \end{align}
  This ``noise'' \(W_t\) is a \emph{random} Wiener process (which will be
  clarified below) and \(x_0\) is our initial value.
  
  The \(g(t, x_t)\) part of the SDE is often referred as \emph{diffusion
  coefficient}. Before moving on, we must carefully define what the term
  \emph{random} means and the best way to begin doing so is to precisely
  define a probability space:
  
  \BeginKnitrBlock{definition}[Probability Space]
  
  \protect\hypertarget{def:unnamed-chunk-1}{}{\label{def:unnamed-chunk-1}
  \iffalse (Probability Space) \fi{} }A triple (\(\Omega\),
  \(\mathcal {U}\), \(\mathcal {P}\)) is called a
  \textit{probability space} provided \(\Omega\) is any set,
  \(\mathcal {U}\) is a \(\sigma\)-algebra of subsets of \(\Omega\) and
  \(\mathcal {P}\) is a probability measure on \(\mathcal {U}\) .
  
  \EndKnitrBlock{definition}
  
  \subsection{Brownian Motion}\label{brownian-motion}
  
  The Brownian motion is the name given to the irregular motion observed
  in the motion of pollen particles suspended in fluid resulting from
  particle collision with atoms or molecules. It is named after Robert
  Brown, the first to have observed the movement in 1828. He noted two
  characteristic in the pollen movement {[}1{]}:
  \begin{itemize}
  \item
    the path of a given particle is very irregular, having a tangent at no
    point
  \item
    the motion of two distinct particles appear to be independent
  \end{itemize}
  The first quantitative works in Brownian motion come from an interest in
  stock price fluctuation by Bachelier in 1900. Albert Einstein also
  leaned over the subject and in 1905 derived the transition density for
  Brownian motion from molecular-kinetic theory of heat {[}1,2{]}.
  
  In 1923, the Wiener process was coined in honor of Norbert Wiener
  mathematical proof of existence of the Brownian motion and stating its
  properties.\footnote{More can be found on {[}3--5{]}.}
  
  \BeginKnitrBlock{definition}[Wiener Process]
  
  \protect\hypertarget{def:unnamed-chunk-2}{}{\label{def:unnamed-chunk-2}
  \iffalse (Wiener Process) \fi{} }Given a probability space (\(\Omega\),
  \(\mathcal {U}\), \(\mathcal {P}\)), a stochastic process \(W_t\)
  defined in this space is a \emph{Wiener process} if it satisfies the
  following properties:
  \begin{itemize}
    \item  $W_{0}=0$
    
    \item The change in $W$, given by $\Delta W = W_{t+\Delta}-W_{t}$, is normally distributed with mean zero and standard deviation $\sqrt{\Delta t}$, meaning that $\Delta W = \epsilon\sqrt{\Delta t}$, where $\epsilon$ is $N(0,1)$.
    
    \item If the increment $\Delta t_1$ does not overlap with the time increment $\Delta t_2$, then $\Delta W_1$ and $\Delta W_2$ are independent.
    
    \item The process is continuous, meaning that there are no jumps in the path, almost surely.
  
  \end{itemize}
  \EndKnitrBlock{definition}
  
  Furthermore, if a process is a Wiener process, we shall have the
  following results by construction:
  \begin{itemize}  
    \item The process is Markovian. This means that the conditional expectation of $W_{t+\Delta t}$ given its entire history is equal to the conditional expectation of $W_{t+\Delta t}$ given today's information. This can be written as: $E[W_{t+\Delta t}|W_t]$.
    
    \item Consider the time interval $[0,t]$ with $n$ equally spaced intervals given by $t_i = \frac{it}{n}$. Then the paths of the Brownian motion have unbounded variation, they are not differentiable. The quadratic variation is given by $\sum_{i=1}^{n}{(Z_{t_i}-Z_{t_{i-1}})^2} \rightarrow t$, meaning that when $n$ increases it stays constant at $t$. 
  \end{itemize}
  \begin{figure}
  
  {\centering \includegraphics{thesis_files/figure-latex/wiener-1} 
  
  }
  
  \caption{A Wiener process trajectory path example \label{wiener}}\label{fig:wiener}
  \end{figure}
  \subsubsection{Correlated Brownian Motions}\label{corr}
  
  Two independent Brownian motions that are correlated can describe a new
  process \(Z_t\). Let \(W_1\) and \(W_2\) be these two \emph{independent}
  Brownian motions and let \(-1 \leq \rho \leq 1\) be a given number. For
  \(0 \leq t \leq T\) define the new process \(Z_t\) as {[}1{]}:
  \begin{align}
  \label{eq:corr_brow}
  Z_t = \rho W_{1,t} + \sqrt{1-\rho^2}W_{2,t}
  \end{align}
  \noindent
  This equation is a linear combination of independent normals at each
  timestep \(t\), so \(Z_t\) is normally distributed. It is proven that
  \(Z\) is a Brownian motion and that \(Z\) and \(W_{1,t}\) have
  correlation \(\rho\) {[}1{]}.
  
  \subsection{It√¥'s Integral}\label{itos-integral}
  
  Formally, the SDE presented in equation \eqref{eq:sde1} is interpreted as
  {[}4--9{]}:
  \begin{align} 
  \label{eq:sde2}
  x_t &= x_0 + \int_{0}^{t}{f(s, x_s)ds} + \int_{0}^{t}{g(s, x_s)dW_s}
  \end{align}
  \noindent
  for some \(f\), \(g\) and \(s \in [0,t]\).
  
  The It√¥ integral can, as the Riemann integral, be approximated by a
  finite sum
  \footnote{There is another important stochastic integral, called the \textit{Stratonovich Integral} that unlike the It√¥'s integral, respects the conventional calculus chain rule. Also, the integral is evaluated at the interval's midpoint, instead of its left extreme. A Stratonovich integral can be expressed as an It√¥ integral and vice versa.}.
  Also, it has a definition as a certain limit. It√¥'s lemma
  \ref{lem:itolemma} plays the same role as the fundamental theorem of
  calculus in allowing to evaluate integrals. It presents an extra term
  not encountered in the conventional calculus theorem that is due to the
  non-smoothness characteristics of Brownian motion paths. It is possible,
  though, to define the integral as the summation below:
  \begin{align}
  Y_{\Delta t}(t) = \sum_{t_k < t}{g(t_k)\Delta W_k}
  \end{align}
  \noindent
  with the usual notions \(t_k = k\Delta t\), and
  \(\Delta W_k = W(t_{k+1})-W(t_k)\). And in a more rigorous form, if the
  limit exists, then the Ito integral is:
  \begin{align}
  Y(t)  = \lim\limits_{\Delta t \to 0} Y_{\Delta t}(t)
  \end{align}
  It is essential that the \emph{forward difference}, that is
  \(W(t_{k+1})-W(t_k)\) is used rather than the backward difference
  \(W(t_{k})-W(t_{k-1})\), which would be wrong.
  
  \BeginKnitrBlock{lemma}[It√¥'s Lemma]
  
  \protect\hypertarget{lem:itolemma}{}{\label{lem:itolemma} \iffalse (It√¥'s
  Lemma) \fi{} } Assume that \(S_t\) has a stochastic differential given
  by:
  \begin{align}
  dS_t = \mu_t dt + \sigma_t dW_t 
  \end{align}
  \noindent
  for \(\mu_t\), \(\sigma_t\) and \(t \in [0,T]\) and that
  \(\mathbb{C}^{2,1} \left( \mathbb{R} \times \left[0, T \right]\right)\).
  Assume \(u: \mathbb{R} \times [0, T] \rightarrow \mathbb{R}\) is
  continuous and that \(\frac{\partial u}{\partial t}\),
  \(\frac{\partial u}{\partial x}\), \(\frac{\partial^2 u}{\partial x^2}\)
  exist and are continuous.
  \begin{align*}
  Y_t := u(S_t, t)
  \end{align*}
  \noindent
  Then Y has the following stochastic differential:
  \begin{align} 
  \label{eq:ito}
  \begin{split}
      dY_t &= \frac{\partial u}{\partial t}dt + \frac{\partial u}{\partial x} dS_t + \frac{1}{2}\frac{\partial^2 u}{\partial x^2}\sigma_t^2 dt  \\[10pt] 
      &= \left( \frac{\partial u}{\partial t} + \mu_t \frac{\partial u}{\partial x} + \frac{1}{2}\frac{\partial^2 u}{\partial x^2}\sigma_t^2 \right) dt + \sigma_t \frac{\partial u}{\partial x} dW_t
  \end{split}
  \end{align}
  \noindent  where the argument of \(\frac{\partial u}{\partial t}\),
  \(\frac{\partial u}{\partial x}\) and
  \(\frac{\partial^2 u}{\partial x^2}\) above is \(\left( S_t, t \right)\)
  .
  
  \EndKnitrBlock{lemma}
  
  Equation \eqref{eq:ito} is the stochastic equivalent to the chain rule,
  also known as It√¥'s formula or It√¥'s chain rule. The proof to this
  theorem is based on the Taylor expansion of the function \(f(S_t, t)\)
  {[}4,6{]}. For practical use you should write out a second-order Taylor
  expansion for the function to be analyzed and apply the multiplication
  table {[}1{]} presented in Table \ref{mat}.
  \begin{table}[ht]
  \centering
  \begin{tabular}{llr}
    \hline 
   & $dt$ & $dW_t$ \\ 
    \hline 
  $dt$ & 0 & 0 \\ 
    $dW_t$ & 0 & $dt$ \\ 
     \hline 
  \end{tabular}
  \caption{Box calculus} 
  \label{mat}
  \end{table}
  \subsubsection{It√¥'s Integral
  Properties}\label{itos-integral-properties}
  
  Let \(f\), \(g\) \(\in\) \(\mathcal{V}\) and let \(0 \leq t_0 < u < T\).
  Then
  \begin{enumerate}[label=(\roman*)]
    \item $\displaystyle \int_{t_0}^{T}{f dB_t} = \int_{t_0}^{u}{f dB_t} + \int_{u}^{T}{f dB_t}$
    \item $\displaystyle \int_{t_0}^{T}{(\alpha f + \beta g) dB_t} = \alpha  \int_{t_0}^{T}{f dB_t} + \beta  \int_{t_0}^{T}{g dB_t}$
    \item $\displaystyle \mathbb{E}\left[ \int_{t_0}^{T}{fdB_t}\right] = 0 $
    \item $\displaystyle \mathbb {E} \left[\left(\int_{0}^{t}H_{s}\,dB_{s}\right)^{2}\right]=\mathbb {E} \left[\int _{0}^{t}H_{s}^{2}\,ds\right]$ (Isometry)
    \item $ \displaystyle \mathbb {E}\left[ \int_{t_0}^{T}{f dB_t \mid \mathcal{F}_{s}} \right] = \int_{t_0}^{s}{f dB_t}, \,\,\,\,\,\,\,\,\,\,\,\,\,\, for \,\, s < T.$  (Martingale\footnote{A martingale is a stochastic process with certain characteristics. The main one is that the expected value in time $t+\Delta t$ for $X$ is the $X$ value in $t$. This means there are no winning strategies when we are dealing with martingales (unlike when we play poker, for example). A Wiener process is a martingale.})
  \end{enumerate}
  \section{Black-Scholes Model}\label{black-scholes-model}
  
  \subsection{Basics}\label{basics}
  
  The Black-Scholes (B-S) model arises from the need to price european
  options in the derivative markets. Derivatives are financial instruments
  traded in the market, stock exchange or over-the-counter (OTC) market,
  whose values depend on the values of an underlying asset. {[}10--12{]}
  \begin{itemize}
  \item
    A call option is a derivative that gives its bearer the right, but not
    the obligation, to purchase a specific asset by a fixed price before
    or on a given date.
  \item
    A put option is a derivative that gives its bearer the right, but not
    the obligation, to sell a specific asset by a fixed price before or on
    a given date.
  \end{itemize}
  The trading price of the option is called the option \emph{premium} and
  the asset from which the option derives is called the \emph{underlying
  asset}. This asset may be interest rates, exchange rates, stock
  exchanges indices, commodities or stocks. The fixed price in contract in
  which the underlying asset might to be bought or sold is the
  \emph{strick price}. The option expiration date is called the
  \emph{maturity}. {[}10,12{]}
  
  There are two major different option types: European and American. The
  difference between these two is that the bearer of the first may
  exercise it only at the end of its life, at its maturity while the
  latter can be exercised at any given time until its maturity.
  {[}10,13{]}
  
  \subsubsection{Geometric Brownian Motion}\label{gbm}
  
  A stochastic process \(S_t\) is a Geometric Brownian Motion\footnote{There
    is an Arithmetic Brownian Motion: \(dS_t = \mu dt + \sigma dB_t\).
    More information can be obtained in {[}1{]}.} if it is described by
  the solution of the following stochastic differential equation
  {[}1,6,14{]}.
  \begin{align}
  dS_t = \mu S_t dt + \sigma S_t dW_t
  \end{align}
  \noindent
  for given constants \(\mu \in {\rm I\!R}\) and \(\sigma > 0\). Also, the
  assumed initial value is positive, \(S_0 >0\).
  
  Figure \ref{fig:gbm} shows the GBM,\footnote{Also known as exponential
    Brownian motion.} which is quite often applied to model the dynamics
  of some financial assets because of its properties {[}15{]}. Equation
  \eqref{eq:sde3} shows the formula to generate a GBM and we provide proof
  of this solution in appendix \ref{bsformula}\footnote{An intuitive proof
    can be found at {[}16{]}.}
  \begin{align} \label{eq:sde3}
  S_t = S_0 \times exp{\left( \left( \mu - \frac{\sigma^2}{2} \right) t + \sigma W_t \right)}, \;\; t > 0
  \end{align}
  \begin{figure}
  
  {\centering \includegraphics{thesis_files/figure-latex/gbm-1} 
  
  }
  
  \caption{A GBM trajectory path example \label{gbm}}\label{fig:gbm}
  \end{figure}
  The Black-Scholes model provides analytical solution to the price of a
  European call at time \(t\) and can be described as follows
  {[}3,10,11{]}:
  \begin{align}
  C(S_{t},t)&=N(d_{1})S_{t}-N(d_{2})Ke^{-r(T-t)}\\[10pt]
  d_{1}&={\frac {1}{\sigma {\sqrt {T-t}}}}\left[\ln \left({\frac {S_{t}}{K}}\right)+\left(r+{\frac {\sigma ^{2}}{2}}\right)(T-t)\right]\\[10pt]
  d_{2}&=d_{1}-\sigma {\sqrt {T-t}}
  \end{align}
  \noindent
  Where:
  \begin{itemize}
  \tightlist
  \item
    \(S_{t}\) is the spot price of the underlying asset at time \(t\)
  \item
    \(r\) is the risk free rate (generally an annual
    rate)\footnote{Assumed to be constant. \label{teste}}
  \item
    \(\sigma\) is the volatility of returns of the underlying asset
    \footnote{See footnote 1.}
  \item
    \(N(\cdot )\) is the cumulative distribution function of the standard
    Gaussian distribution
  \item
    \(K\) is the strike price
  \item
    \(T-t\) is the time to maturity
  \end{itemize}
  \noindent
  Also, the stock price path is a Geometric Brownian Motion as previously
  stated, and is under the risk-neutral measure with the following
  dynamics {[}3,17{]}:
  \begin{align}
  dS_{t} = (r-q)S_td_t+\sigma S_t dW_t
  \end{align}
  \noindent
  Here \(W_t\) is a Wiener process {[}10,17{]}, \(r\) is the risk free
  rate and \(q\) is the dividend
  yield\footnote{$r$ and $q$ are assumed to be constant.} and \(t\)
  denotes the current point in time.
  
  \subsection{Limitations}\label{limitations}
  
  Although the Black-Scholes is very popular and the \emph{de facto}
  standard in the market there are implications to the B-S model
  assumptions that affect the results and that are unrealistic. The main
  assumption that does not hold up is the deterministic (constant)
  volatility, that can more accurately be described as a stochastic
  process since we observe that small moves usually are followed by small
  moves and large moves by large moves. {[}3,11{]}
  
  Other assumptions that are critical to the B-S model and are not always
  observed in practice refer to the asset's continuity through time (no
  jumps), being allowed to perform continuous hedge without transactions
  costs and normal (Gaussian) returns.
  
  Most models focus on the volatility problem because transaction costs
  often implies rises in volatility and that fat-tails (abnormal) returns
  can be simulated by stochastic volatility and market or volatility
  jumps.
  
  \section{Stochastic Volatility
  models}\label{stochastic-volatility-models}
  
  Introducing stochastic volatility to models brings complexity, but
  enables modeling some features observed in reality that are crucial,
  like the randomic market volatility effects, skewness (market returns
  are more realistically modeled) and volatility smile\footnote{The name
    derives from the concave shape of the graph, which resembles a smile.}
  (see Figure \ref{fig:smile}). This kind of model is applied highly
  succesfully in foreign exchange and credit markets.
  
  \BeginKnitrBlock{definition}[Volatility Smile]
  
  \protect\hypertarget{def:unnamed-chunk-3}{}{\label{def:unnamed-chunk-3}
  \iffalse (Volatility Smile) \fi{} }Volatility smiles are implied
  volatility patterns that arise in pricing financial options. In
  particular for a given expiration, options whose strike price differs
  substantially from the underlying asset's price command higher prices
  (and thus implied volatilities) than what is suggested by standard
  option pricing models. These options are said to be either deep
  in-the-money or out-of-the-money.
  
  \EndKnitrBlock{definition}
  
  Furthermore, stochastic volatility models use statistical methods as
  foundations to price and forecast options' behaviors and the
  underlying's security volatility is arbitrary. The Heston, the \(3/2\)
  and other models, like the GARCH\footnote{generalized autoregressive
    conditional heteroscedasticity. {[}18{]}} and SABR,\footnote{stochastic
    alpha, beta, rho. {[}20{]}} are considered standard smile models.
  \begin{figure}
  
  {\centering \includegraphics{thesis_files/figure-latex/smile-1} 
  
  }
  
  \caption{Volatility Smile \label{smile}}\label{fig:smile}
  \end{figure}
  \subsection{Cox-Ingersoll-Ross model}\label{cir}
  
  The Cox-Ingersoll-Ross (CIR) model is a well-known short-rate model that
  describes the interest rate movements driven by one source of market
  risk. The dynamics are described as follows {[}21,22{]}:
  \begin{align}
  \label{eq:cir}
  dr_t &= k(\theta - r_t)dt + \sigma \sqrt{r_t} dB_t
  \end{align}
  \noindent
  Where, \(r_t\) is the short rate interest described by parameters
  \(\kappa\) the speed of mean reversion, \(\theta\) the long-run mean
  variance and \(\sigma\) the volatility of the variance process.
  
  This model has been widely used to describe the dynamics of the short
  rate interest because it has some fundamental features like intuitive
  parametrization, nonnegativity and pricing formulas. Besides, it takes
  account of anticipations, risk aversion, investment alternatives and
  preferences about consumption timing and allows for detailed predictions
  about how changes in a wide range of underlying variables affect the
  term structure{[}21{]}. Furthermore, this equation constitutes one of
  the two Heston model equations with the volatility taking the short rate
  interest place.
  
  \subsection{Heston Model}\label{hes1}
  
  Heston model was introduced in 1993 by Steven Heston to solve the
  deterministic volatility problems. It was designed to analize bond and
  currency options and it introduced the following equations, which
  represent the dynamics of the stock price and the variance processes
  under the risk-neutral measure {[}22,23{]}:
  \begin{align}
  \label{eq:heston}
  dS_t &= \mu S_t dt + \sqrt{V_t} S_t dW^*_t \\
  dV_t &=  \kappa (\theta - V_t)dt + \sigma \sqrt{V_t} dB_t
  \label{eq:hesvar}
  \end{align}
  The second equation, as described in Section \ref{cir}, is the CIR model
  equation. The first equation states the asset price process. \(\mu\) is
  the asset's rate of return, \(dW_{t,1}\) and \(dW_{t,2}\) are two
  correlated wiener processes with correlation coefficient of \(\rho\).
  
  \section{Numerical Methods}\label{numerical-methods}
  
  Numerical methods are tools that are often applied to solve stochastic
  differential equations because most of these do not have explicit
  solution. This means that we are not able to solve these equations using
  symbolic computation. Although we are unable to find an analitical
  solution, when facing real problems, the approximation given by a
  numerical method is often sufficient. Alongside the analytical issue,
  the need to calculate the SDE's trajectory through time is the main
  reason why studying numerical methods is so important. An implementation
  of a numerical method is called a numerical algorithm.
  
  We will simulate sample paths of time discrete approximations
  implemented in the R programming language {[}24{]} that we base on a
  finite discretization of a time interval \([t_0, T]\). We shall generate
  approximate values of the sample path for each step contained in the
  discretized interval {[}25{]}.
  
  In the fixed step methods, the distance between two contiguous points is
  \(d_i = t_i - t_{i-1} = \frac{T-t_0}{N} \;\;\; i \leq N \in \mathbb{N}\).
  \(N\) being the time interval partition number.
  
  According to Kloeden {[}25{]}, in the stochastic realm, simulated sample
  paths can be statistically analysed to find how good an approximation is
  compared to an exact solution. Moreover, the computational costs such as
  time and memory increases polynomially with the problem's dimension,
  which is good, and it is possible to apply variance reduction methods
  that allow a considerable decrease in the required sample size.
  
  \subsection{Convergence}\label{convergence}
  
  As soon as we talk about numerical methods we are required to approach
  the topic of approximations and how to handle them. Methods efficiency
  receive the name of \emph{convergence order}. In the SDE domain there
  are two main methods of convergence, that are classified according to
  their criteria. Firstly, we present the \emph{strong order of
  convergence}. A method is said to have strong convergence \(\delta\) to
  \(Y\) if a time discretized \(Y_{\delta}\) of a continous-time process
  \(Y\), with \(\delta\) being the maximum time increment of the
  discretization, and for any fixed time horizon \(T\) holds true that
  {[}15{]}:
  \begin{align*}
  \mathbb{E} \mid Y_{\delta}(T) - Y(T) \mid \leq C \delta^{\gamma}, \,\,\, \forall \delta < \delta_0
  \end{align*}
  with \(\delta_0 > 0\) and \(\mathcal{C}\) a constant not depending on
  \(\delta\). Strong convergence addresses the problem of solutions'
  trajectories. For specific conditions, the Euler method has strong
  convergence order \(\gamma = \frac{1}{2}\). Furthermore, there is the
  \emph{weak order of convergence}:
  \begin{align*}
  \mid  \mathbb{E}p(Y_n) - \mathbb{E}p(Y(\tau)) \mid \leq C \Delta t^{\gamma}
  \end{align*}
  Strong and weak convergence are not mutually exclusive {[}15{]}. That
  means that a method with a given strong order of convergence might have
  a higher weak order of convergence too. This is the case for the Euler
  scheme, with a strong order of convergence of \(1/2\) and a weak order
  of \(1\) (under some conditions). For a more detailed and rigorous
  explanation of convergence we recommend consulting {[}26{]}.
  
  It is worth noting that, altough schemes have a given convergence order,
  it is not unusual that they behave better than their order for some SDEs
  specifications.
  
  \subsection{Discretization}\label{discretization}
  
  We know that convergence is an important feature to a numerical method
  and studies have found not all time discrete possible approximations of
  an SDE converge in a useful sense to the solution process as the step
  size adopted tends toward zero {[}27,28{]}. Moreover, particularly for
  SDEs, some of the more rapidly convergent methods available for ordinary
  differential equations (ODE) do not work, such as higher order
  Runge-Kutta methods.\footnote{The euler method is the simplest
    Runge-Kutta method.}
  
  One of the methods that do work for ODEs and SDEs is the Euler method,
  named after the Swiss mathematician Leonhard Euler. Figure
  \ref{fig:euler} shows an example of an implementation for the Newton's
  cooling law with timestep of 2 seconds compared to its analytical
  solution. This method (\emph{a.k.a.} forward Euler method) is a
  first-order numerical procedure. It is the most basic explicit
  method\footnote{Explicit methods calculate the state of a system at a
    later time from the state of the system at the current time.
    Mathematically we have something like \(Y(t+\Delta t)=F(Y(t))\,\).}
  for numerical integration.
  \begin{figure}
  
  {\centering \includegraphics{thesis_files/figure-latex/euler-1} 
  
  }
  
  \caption{Analytical x Euler solutions \label{euler}}\label{fig:euler}
  \end{figure}
  The method is first-order, as stated above, this means that the error in
  each step is a proportion of the square of the step size. Also, the
  global error at a given time is a function of the step size. We proceed
  to apply the Euler method to SDEs. Consider the equation:
  \begin{align}
  dS_t &= \mu(S_t,t) dt + \sigma(S_t,t) dW_t
  \end{align}
  \(dW_t\) is the Brownian motion, \(\mu\) and \(\sigma\) are functions
  depending on \(S_t\) and \(t\), over an interval \([0,T]\), and we want
  to discretize it as \(0 = t_1 < t2 < \cdots < t_m = T\) with increments
  equally spaced \(\Delta t\).
  
  Integrating it from \(t\) to \(\Delta t\) we have the starting point for
  our (and any) discretization scheme:
  \begin{align}
  \label{eq:disc1}
  S_{t+\Delta t} &= S_t + \int_{t}^{\Delta t}{\mu(S_u,u)}du + \int_{t}^{\Delta t}{\sigma(S_u,u)} dW_u
  \end{align}
  To use the Euler discretization is the equivalent of approximating
  integrals using the left-point rule as in Figure
  \ref{graph_euler}\footnote{See Kiusalaas {[}29{]}}, we then have:
  \begin{align*}
   \int_{t}^{t+\Delta t}{\mu(S_u,u)} dW_u &\approx \mu(S_t,t) \int_{t}^{t+\Delta t}dW_u\\
  &= \mu(S_t,t) (W_{t+\Delta t} - W_t)  \\
   \int_{t}^{t+\Delta t}{\sigma(S_u,u)} dW_u &\approx \sigma(S_t,t) \int_{t}^{t+\Delta t}dW_u 
  = \sigma(S_t,t) (W_{t+\Delta t} - W_t)  \\
  &= \sigma(S_t,t) \sqrt{\Delta t} Z
  \end{align*}
  \(W_{t+\Delta t}-W_t\) and \(\sqrt{\Delta t}Z\) have identical
  distribution, \(Z\) being a standard Gaussian variable. The Euler
  discretization of equation \eqref{eq:disc1} is then:
  \begin{align}
  \label{eq:disc2}
  S_{t+\Delta t} &= S_t + \mu(S_t,t)\Delta t + \sigma(S_t,t)\sqrt{\Delta t}Z
  \end{align}
  \begin{figure}
  \begin{center}
      \includegraphics[width=100mm]{figure/euler_screen.png}
      \caption{Graphical representation of Euler‚Äôs formula}\label{graph_euler}
      \caption*{\scriptsize{Source: Numerical methods in Engineering with Python 3.}}
  \end{center}
  \end{figure}
  \subsubsection{Euler method - Heston
  model}\label{euler-method---heston-model}
  
  We now proceed to apply the method to our model of interest. We retake
  the equations \eqref{eq:heston} and \eqref{eq:hesvar}. We begin showing how
  to discretize the latter {[}15,26{]}:
  \begin{align}
  \label{eq:hesvareuler}
  V_{t+\Delta t} = V_t+ \int_{t}^{t+\Delta t}{\kappa (\theta - V_u) du} + \int_{t}^{t+\Delta t}{\sigma \sqrt{V_u} dB_u}
  \end{align}
  Which discretized turns out as:
  \begin{align*}
   \int_{t}^{t+\Delta t}{\kappa (\theta - V_u)} du &\approx \kappa (\theta - V_t) \Delta t\\
   \int_{t}^{t+\Delta t}{\sigma \sqrt{V_u}} dB_t &\approx \sigma \sqrt{V_t} (W_{t+\Delta t}-W_t)
  = \sigma \sqrt{V_t \Delta t} Z_v
  \end{align*}
  And leaves us with:
  \begin{align}
  V_{t+\Delta t} = V_t + \kappa (\theta - V_t) \Delta t + \sigma \sqrt{V_t \Delta t} Z_v
  \end{align}
  \(Z_v\) is a standard normal variable. To avoid problems with negative
  values in \(\sqrt{V_t}\) we apply the \emph{full truncation} scheme,
  which substitutes \(V_t\) with \(V_t^+ = max(0, V_t)\).\footnote{Another
    possible scheme (not used in this work) is the \emph{reflection}
    scheme where we replace \(V_t\) with \(\mid V_t \mid\)}
  
  For the \(S_t\) SDE we proceed similarly:
  \begin{align}
  \label{eq:heseuler}
  S_{t+\Delta t} = S_t+ \mu \int_{t}^{t+\Delta t}{ S_u du} + \int_{t}^{t+\Delta t}{\sqrt{V_u} S_u dW_u}
  \end{align}
  Discretizing we have:
  \begin{align*}
   \int_{t}^{t+\Delta t}{S_u} du &\approx S_t \Delta t\\
   \int_{t}^{t+\Delta t}{\sqrt{V_u} S_u} dW_u &\approx \sqrt{V_t} S_t (W_{t+\Delta t}-W_t)\\
  &= \sqrt{V_t \Delta t} S_t Z_s
  \end{align*}
  \(Z_s\) is a standard normal variable with correlation \(\rho\) with
  \(Z_v\). We have:
  \begin{align}
  S_{t+\Delta t} = S_t + \mu S_t \Delta t + \sqrt{V_t \Delta t} S_t Z_s
  \end{align}
  \subsection{Stability}\label{stability}
  
  Most differential equations, deterministic or stochastic, cannot be
  solved explicitly {[}25{]}. Hence, stability studies begin with
  computers and is associated with numerical methods and approximations.
  Convergent methods were resulting in bigger errors than what was
  expected that could not be only due to discretization error. Eventually,
  scientists discovered that this unexpected problem was caused by
  accumulation of successive truncation errors. Figure \ref{fig:stab}
  retakes the cooling example previously approached to show instability
  due to an increase in size of the timestep and extending to \(600\)
  seconds. The top plot, with a step of \(25\) still converges to the real
  solution, but we already observe an odd behaviour since the numerical
  method doesn't follow the analytical solution, but instead revolver
  around it until convergence. The bottom plot, presents a small increase
  in the step \(h = 29\), and this small increment is enough results in
  numbers completely off target.
  \begin{figure}
  
  {\centering \includegraphics{thesis_files/figure-latex/stab-1} 
  
  }
  
  \caption{Euler's stability whith different timesteps \label{stab}}\label{fig:stab}
  \end{figure}
  We know that binary machines like computers are not able to represent
  all the real numbers, but only a subset of them. Thus, solving these
  errors is not straightforward since it's not possible to eliminate
  \emph{all} truncation error when using a computer and dealing with
  numerical solutions. When faced to an incorrect (not acceptable)
  solution, we have to evaluate and distinguish between two distinct
  situations:
  \begin{itemize}
    \item [i] Rounding errors are considerably amplified by the algorithm. This situation is called numerical instability.
    \item [ii] Small perturbations of data generate large changes in the solution. This is termed an ill-conditioned (or sensitive) problem.
  \end{itemize}
  Examples of these two classes of problem can be found in {[}23{]}.
  
  Stiff equations appear very often in mathematical problems and refer to
  differential equations for which a numerical methods might be unstable
  for not small enough stepsizes {[}30{]}. A differential equation of the
  form \(y' = f(t,y)\), if its exact solution \(y(t)\) includes a term
  that decays exponentially to zero as \(t\) increases, but whose
  derivatives are greater in magnitude than the term itself. In other
  words, if it requires a significant depression of the stepsize to avoid
  stability lost. This is a loose definition but, since we are dealing
  with numerical methods a proper mathematical definition isn't required.
  Tipically, these equations are of the form \(e^{-ct}\), where \(c\) is a
  large positive constant {[}31{]}. A practical example of the stiff
  behavior is the following differential equation {[}32{]}:
  \begin{align*}
  y' = -100y, \,\,\,\,\,\, t > 0, \,\,\,\,\,\, y_0 = 1
  \end{align*}
  Whose exact solution is \(y_t = e^{-100 t}\) and goes to zero as \(t\)
  increases. Applying Euler's method to this equation with \(h=0.1\) we
  stumble in the following equation
  \begin{align*}
  y_{n+1} = y_{n} - 100 h y_{n} = -9y_{n}
  \end{align*}
  which is wrong, since it yields an exponencially growing solution
  \(y_n = (-9)^n\). On the other hand, if our timestep is smaller
  \(h = 10^{-3}\), our solution using Euler's method becomes
  \(y_n = (0.9)^n\). This solution leads to an accurate behavior regarding
  the exact solution, it rapidily decays to zero.
  
  Sometimes, it is interesting to rank differential equations that are
  more or less stiff. Thus, people compute the quotient of the largest and
  the smallest eigenvalues of a linear system. They call it the equations'
  \textit{stiffness ratio} and, usually the bigger the stiffness ratio,
  the more likely is to be stiff {[}30{]}.
  
  \subsubsection{Stability Domain}\label{stability-domain}
  
  Let's take the equation:
  \begin{align}
  y' = \lambda y,  \,\,\,\,\,\, t \geq 0, \,\,\,\,\,\,\,\,\,\,\,\,\,\, y_0 = 1
  \end{align}
  where \(\lambda \in \mathbb{C}\) or in other terms
  \(\lambda = \lambda_r + i \lambda_i\) and whose solution is
  \(y+t = e^{\lambda t}\). We can rewrite this equation as a system:
  \begin{align}
  \frac{d}{dt} \begin{bmatrix} y^1 \\ y^2 \end{bmatrix} = 
  \begin{pmatrix} 
  \lambda_r & - \lambda_i \\
  \lambda_i & - \lambda_r 
  \end{pmatrix}
  \begin{bmatrix} y^1 \\ y^2 \end{bmatrix}
  \end{align}
  The \(\lim_{t \to \infty} y_t = 0\) if and only if
  \(\mathbb{R} \lambda < 0\). The \emph{linear stability domain}
  \(\mathcal{D}\) is defined as the set of all numbers
  \(\Delta \lambda \in mathbb{C}\) such that
  \(\lim_{n \to \infty y+n = 0}\), with \(\Delta > 0\) being the stepsize.
  Or, as stated in Kloeden {[}25{]}, the suitable values of the stepsize
  are expressed in terms of \emph{region of absolute stability},
  consisting of the complex numbers \(\lambda \Delta\) for which an error
  in \(y_0\) at \(t_0\) will not grow in subsequent iterations of the
  method.
  
  Without entering all the details, for these we recommend {[}25,30,32{]},
  the euler's stability domain is:
  \begin{align*}
  \mathcal{D}_{Euler} = z \in \mathbb{C} : \mid 1 + z \mid < 1
  \end{align*}
  which represents the interior of a complex disc of unit radius and
  centre \(z = -1\) as can be seen in Figure \ref{stab2}, on the left. The
  right side of the Figure \ref{stab2} shows the stability region called
  A-stability.\footnote{Mathematically:
    \(\mathcal{D} \subseteq \left\{ z \in \mathbb{C} : \mathbb{R} z < 0 \right\}\).}
  If a method is A-stable, the stepsize \(\Delta\) is only constraint by
  accuracy.
  \begin{figure}
  
  \includegraphics{thesis_files/figure-latex/stab2-1} \hfill{}
  
  \caption{Stability domains \label{stab2}}\label{fig:stab2}
  \end{figure}
  Thereby, we claim that stability method study is an important topic,
  since it enables achieving solutions that are good to stiff equations
  without having to overly reduce our timesteps which can be very
  computationally costly.
  
  \chapter{The Heston Model Implementation}\label{implement}
  
  \chapter{This chunk ensures that the thesisdown package
  is}\label{this-chunk-ensures-that-the-thesisdown-package-is}
  
  \chapter{Conclusion}\label{conclusao}
  
  \chapter{Black-Scholes formula}\label{bsformula}
  
  \chapter*{References}\label{references}
  \addcontentsline{toc}{chapter}{References}
  
  \hypertarget{refs}{}
  \hypertarget{ref-ubbo}{}
  {[}1{]} Wiersema, U.F. Brownian motion calculus. 2008.
  
  \hypertarget{ref-karatzas2012brownian}{}
  {[}2{]} Karatzas, I.; Shreve, S. Brownian motion and stochastic
  calculus. 2012.
  
  \hypertarget{ref-helgadottir2016option}{}
  {[}3{]} Helgad√≥ttir, A.D.; Ionescu, L. Option pricing within the heston
  model. 2016.
  
  \hypertarget{ref-evans}{}
  {[}4{]} Evans, L.C. An introduction to stochastic differential
  equations. 2012.
  
  \hypertarget{ref-rosenthal}{}
  {[}5{]} Rosenthal, J.S. A first look at rigorous probability theory.
  2006.
  
  \hypertarget{ref-tong2012option}{}
  Tong, Z. (2012). Option pricing with long memory stochastic volatility
  models.
  
  \hypertarget{ref-steele2012stochastic}{}
  {[}7{]} Steele, J.M. Stochastic calculus and financial applications.
  2012.
  
  \hypertarget{ref-ito1951}{}
  {[}8{]} It≈ç, K. On stochastic differential equations. 1951.
  
  \hypertarget{ref-ito1962}{}
  {[}9{]} It√¥, K. The brownian motion and tensor fields on riemannian
  manifold. Proc. Int. Congr. Math., Stockholm, v. 2, 1962.
  
  \hypertarget{ref-black1973pricing}{}
  {[}10{]} Black, F.; Scholes, M. The pricing of options and corporate
  liabilities. Journal of political economy, v. 81, n. 3, p. 637--654,
  1973.
  
  \hypertarget{ref-yang2013valuing}{}
  {[}11{]} Yang, Y. Valuing a european option with the heston model. 2013.
  
  \hypertarget{ref-salomao2011precificaccao}{}
  {[}12{]} Salom√£o, M. de F. Precifica√ß√£o de op√ß√µes financeiras: Um estudo
  sobre os modelos de black scholes e garch. 2011.
  
  \hypertarget{ref-merton1973theory}{}
  {[}13{]} Merton, R.C. Theory of rational option pricing. The Bell
  Journal of economics and management science, p. 141--183, 1973.
  
  \hypertarget{ref-tsay2005analysis}{}
  {[}14{]} Tsay, R.S. Analysis of financial time series. 2005.
  
  \hypertarget{ref-iacus2009simulation}{}
  {[}15{]} Iacus, S.M. Simulation and inference for stochastic
  differential equations: With r examples. 2009.
  
  \hypertarget{ref-krouglov2006intuitive}{}
  {[}16{]} Krouglov, A. Intuitive proof of black-scholes formula based on
  arbitrage and properties of lognormal distribution. arXiv preprint
  physics/0612022, 2006.
  
  \hypertarget{ref-nmof}{}
  {[}17{]} Gilli, M.; Maringer, D.; et al. Numerical methods and
  optimization in finance. Waltham, MA, USA: 2011.
  
  \hypertarget{ref-engle1982autoregressive}{}
  {[}18{]} Engle, R.F. Autoregressive conditional heteroscedasticity with
  estimates of the variance of united kingdom inflation. Econometrica:
  Journal of the Econometric Society, p. 987--1007, 1982.
  
  \hypertarget{ref-bollerslev1986generalized}{}
  {[}19{]} Bollerslev, T. Generalized autoregressive conditional
  heteroskedasticity. Journal of econometrics, v. 31, n. 3, p. 307--327,
  1986.
  
  \hypertarget{ref-hagan2014arbitrage}{}
  {[}20{]} Hagan, P.S.; Kumar, D.; et al. Arbitrage-free sabr. Wilmott, v.
  2014, n. 69, p. 60--75, 2014.
  
  \hypertarget{ref-cox1985theory}{}
  {[}21{]} Cox, J.C.; Ingersoll Jr, J.E.; et al. A theory of the term
  structure of interest rates. Econometrica: Journal of the Econometric
  Society, p. 385--407, 1985.
  
  \hypertarget{ref-heston1993closed}{}
  {[}22{]} Heston, S.L. A closed-form solution for options with stochastic
  volatility with applications to bond and currency options. Review of
  financial studies, v. 6, n. 2, p. 327--343, 1993.
  
  \hypertarget{ref-gilli_numerical_2011}{}
  {[}23{]} Gilli, M.; Maringer, D.; et al. Numerical methods and
  optimization in finance. 2011.
  
  \hypertarget{ref-rlang}{}
  {[}24{]} R Core Team. R: A language and environment for statistical
  computing. Vienna, Austria: 2017.
  
  \hypertarget{ref-kloeden1992}{}
  {[}25{]} Kloeden, P.E.; Platen, E. Numerical solution of stochastic
  differential equations springer-verlag. 1992.
  
  \hypertarget{ref-higham2001}{}
  {[}26{]} Higham, D.J. An algorithmic introduction to numerical
  simulation of stochastic differential equations. SIAM review, v. 43, n.
  3, p. 525--546, 2001.
  
  \hypertarget{ref-clements1973well}{}
  {[}27{]} Clements, D.; Anderson, B. Well-behaved it√¥ equations with
  simulations that always misbehave. IEEE Transactions on Automatic
  Control, v. 18, n. 6, p. 676--677, 1973.
  
  \hypertarget{ref-clark1980maximum}{}
  {[}28{]} Clark, J.M., Cameron, R. The maximum rate of convergence of
  discrete approximations for stochastic differential equations. In:
  Stochastic differential systems filtering and control. 1980, p.
  162--171.
  
  \hypertarget{ref-kiusalaas2013numerical}{}
  {[}29{]} Kiusalaas, J. Numerical methods in engineering with python 3.
  2013.
  
  \hypertarget{ref-iserles}{}
  {[}30{]} Iserles, A. A first course in the numerical analysis of
  differential equations. 2009.
  
  \hypertarget{ref-burden2001}{}
  {[}31{]} Burden, R.L.; Faires, J.D. Numerical analysis. 2001.
  Brooks/Cole, USA, 2001.
  
  \hypertarget{ref-lambers}{}
  {[}32{]} Lambers, J.V.; Sumner, A.C. Explorations in numerical analysis.
  University o California at Irvine, 2016.


  % Index?

\end{document}
