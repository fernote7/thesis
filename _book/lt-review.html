<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title></title>
  <meta name="description" content="">
  <meta name="generator" content="bookdown 0.4 and GitBook 2.6.7">

  <meta property="og:title" content="" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="" />
  
  
  

<meta name="author" content="Fernando O. Teixeira">


<meta name="date" content="2017-09-16">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="the-heston-model-implementation.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />










</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="1" data-path="lt-review.html"><a href="lt-review.html"><i class="fa fa-check"></i><b>1</b> Literature Review</a><ul>
<li class="chapter" data-level="1.1" data-path="lt-review.html"><a href="lt-review.html#stochastic-calculus"><i class="fa fa-check"></i><b>1.1</b> Stochastic Calculus</a><ul>
<li class="chapter" data-level="1.1.1" data-path="lt-review.html"><a href="lt-review.html#the-stochastic-differential-equation---sde"><i class="fa fa-check"></i><b>1.1.1</b> The Stochastic differential equation - SDE</a></li>
<li class="chapter" data-level="1.1.2" data-path="lt-review.html"><a href="lt-review.html#brownian-motion"><i class="fa fa-check"></i><b>1.1.2</b> Brownian Motion</a></li>
<li class="chapter" data-level="1.1.3" data-path="lt-review.html"><a href="lt-review.html#itos-integral"><i class="fa fa-check"></i><b>1.1.3</b> Itô’s Integral</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="lt-review.html"><a href="lt-review.html#black-scholes-model"><i class="fa fa-check"></i><b>1.2</b> Black-Scholes Model</a><ul>
<li class="chapter" data-level="1.2.1" data-path="lt-review.html"><a href="lt-review.html#basics"><i class="fa fa-check"></i><b>1.2.1</b> Basics</a></li>
<li class="chapter" data-level="1.2.2" data-path="lt-review.html"><a href="lt-review.html#the-model"><i class="fa fa-check"></i><b>1.2.2</b> The model</a></li>
<li class="chapter" data-level="1.2.3" data-path="lt-review.html"><a href="lt-review.html#limitations"><i class="fa fa-check"></i><b>1.2.3</b> Limitations</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="lt-review.html"><a href="lt-review.html#stochastic-volatility-models"><i class="fa fa-check"></i><b>1.3</b> Stochastic Volatility models</a><ul>
<li class="chapter" data-level="1.3.1" data-path="lt-review.html"><a href="lt-review.html#cir"><i class="fa fa-check"></i><b>1.3.1</b> Cox-Ingersoll-Ross model</a></li>
<li class="chapter" data-level="1.3.2" data-path="lt-review.html"><a href="lt-review.html#hes1"><i class="fa fa-check"></i><b>1.3.2</b> Heston Model</a></li>
<li class="chapter" data-level="1.3.3" data-path="lt-review.html"><a href="lt-review.html#other-models"><i class="fa fa-check"></i><b>1.3.3</b> Other Models</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="lt-review.html"><a href="lt-review.html#numerical-methods"><i class="fa fa-check"></i><b>1.4</b> Numerical Methods</a><ul>
<li class="chapter" data-level="1.4.1" data-path="lt-review.html"><a href="lt-review.html#convergence"><i class="fa fa-check"></i><b>1.4.1</b> Convergence</a></li>
<li class="chapter" data-level="1.4.2" data-path="lt-review.html"><a href="lt-review.html#discretization"><i class="fa fa-check"></i><b>1.4.2</b> Discretization</a></li>
<li class="chapter" data-level="1.4.3" data-path="lt-review.html"><a href="lt-review.html#stability"><i class="fa fa-check"></i><b>1.4.3</b> Stability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="the-heston-model-implementation.html"><a href="the-heston-model-implementation.html"><i class="fa fa-check"></i><b>2</b> The Heston Model Implementation</a><ul>
<li class="chapter" data-level="2.1" data-path="the-heston-model-implementation.html"><a href="the-heston-model-implementation.html#characteristic-function"><i class="fa fa-check"></i><b>2.1</b> Characteristic Function</a></li>
<li class="chapter" data-level="2.2" data-path="the-heston-model-implementation.html"><a href="the-heston-model-implementation.html#euler-scheme"><i class="fa fa-check"></i><b>2.2</b> Euler Scheme</a></li>
<li class="chapter" data-level="2.3" data-path="the-heston-model-implementation.html"><a href="the-heston-model-implementation.html#kahl-jackel"><i class="fa fa-check"></i><b>2.3</b> Kahl-Jackel</a></li>
<li class="chapter" data-level="2.4" data-path="the-heston-model-implementation.html"><a href="the-heston-model-implementation.html#exact-algorithm"><i class="fa fa-check"></i><b>2.4</b> Exact Algorithm</a><ul>
<li class="chapter" data-level="2.4.1" data-path="the-heston-model-implementation.html"><a href="the-heston-model-implementation.html#generate-a-sample-of-v_t-given-v_0"><i class="fa fa-check"></i><b>2.4.1</b> Generate a sample of <span class="math inline">\(V_t\)</span> given <span class="math inline">\(V_0\)</span></a></li>
<li class="chapter" data-level="2.4.2" data-path="the-heston-model-implementation.html"><a href="the-heston-model-implementation.html#generate-a-sample-of-int_0t-v_sds-given-v_t-v_0"><i class="fa fa-check"></i><b>2.4.2</b> Generate a sample of <span class="math inline">\(\int_0^t V_sds\)</span> given <span class="math inline">\(V_t\)</span>, <span class="math inline">\(V_0\)</span></a></li>
<li class="chapter" data-level="2.4.3" data-path="the-heston-model-implementation.html"><a href="the-heston-model-implementation.html#compute-int_0t-sqrtv_sdb_s-given-v_t-v_0-and-int_0t-v_sds"><i class="fa fa-check"></i><b>2.4.3</b> Compute <span class="math inline">\(\int_0^t \sqrt{V_s}dB_s\)</span> given <span class="math inline">\(V_t\)</span>, <span class="math inline">\(V_0\)</span> and <span class="math inline">\(\int_0^t V_sds\)</span></a></li>
<li class="chapter" data-level="2.4.4" data-path="the-heston-model-implementation.html"><a href="the-heston-model-implementation.html#limitations-1"><i class="fa fa-check"></i><b>2.4.4</b> Limitations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="results.html"><a href="results.html"><i class="fa fa-check"></i><b>3</b> Results</a></li>
<li class="chapter" data-level="4" data-path="conclusion.html"><a href="conclusion.html"><i class="fa fa-check"></i><b>4</b> Conclusion</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="bsformula.html"><a href="bsformula.html"><i class="fa fa-check"></i><b>A</b> Black-Scholes formula</a></li>
<li class="chapter" data-level="B" data-path="bessel.html"><a href="bessel.html"><i class="fa fa-check"></i><b>B</b> Bessel Function</a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="lt-review" class="section level1">
<h1><span class="header-section-number">Chapter 1</span> Literature Review</h1>
<p>This chapter presents the concepts of stochastic calculus, from the historic conception of how it first arose through the basic principles and applications in finance. We address with more care the classical Black-Scholes model and its limitations and the Heston model. This model is also well known, it brings the concept of stochastic volatility in it, which brings its results closer to reality.</p>
<div id="stochastic-calculus" class="section level2">
<h2><span class="header-section-number">1.1</span> Stochastic Calculus</h2>
<p>Stochastic calculus arises from stochastic processes and allows the creation of a theory of integration where both the integrand and integrator terms are stochastic processes. Stochastic calculus was created by the Japanese mathematician Kiyosi Itô  in the 1940s and 1950s and is used for modeling financial options and in another wide variety of fields <span class="citation">[38]</span>. In this chapter we present the historical contexts in which the tools and models are used, but our focus is introducing the concepts and notations that will be further used in our work.</p>
<div id="the-stochastic-differential-equation---sde" class="section level3">
<h3><span class="header-section-number">1.1.1</span> The Stochastic differential equation - SDE</h3>
<p>At first, before introducing stochastic differential equation, it is helpful to start with ordinary differential equation. Let <span class="math inline">\(x(t) = x_t\)</span> denote a population at time <span class="math inline">\(t\)</span> so that the change in the population at time <span class="math inline">\(t\)</span> is given by the following deterministic differential equation:</p>
<span class="math display">\[\begin{align}
dx_t &amp;= f(t, x_t)dt \\
x(0) &amp;= x_0 \nonumber
\end{align}\]</span>
<p>We now add a ``noise’’ to this equation:</p>
<span class="math display">\[\begin{align} \label{eq:sde1}
dx_t &amp;= \overbrace{\underbrace{f(t, x_t)}_\text{drift}dt}^\text{deterministic} + \overbrace{\underbrace{g(t, x_t)}_\text{diffusion}dW_t}^\text{random shock} \\
x(0) &amp;= x_0 \nonumber
\end{align}\]</span>
<p>This ``noise’’ <span class="math inline">\(dW_t\)</span> is a <em>random</em> Wiener process time derivative (which will be clarified below) and <span class="math inline">\(x_0\)</span> is our initial value.</p>
<p>The <span class="math inline">\(g(t, x_t)\)</span> part of the SDE is often referred as a <em>diffusion process</em>, these usually have a continuous paths. Before moving on, we must carefully define what the term <em>random</em> means and the best way to begin doing so is to precisely define a probability space:</p>

</div>
<div id="brownian-motion" class="section level3">
<h3><span class="header-section-number">1.1.2</span> Brownian Motion</h3>
<p>The Brownian motion is the name given to the irregular motion observed in the motion of pollen particles suspended in fluid resulting from particle collision with atoms or molecules. It is named after Robert Brown, the first to have observed the movement in 1828. He noted two characteristic in the pollen movement <span class="citation">[38]</span>:</p>
<ul>
<li><p>the path of a given particle is very irregular, having a tangent at no point</p></li>
<li><p>the motion of two distinct particles appear to be independent</p></li>
</ul>
<p>The first quantitative works in Brownian motion come from an interest in stock price fluctuation by Bachelier in 1900. Albert Einstein also leaned over the subject and in 1905 derived the transition density for Brownian motion from molecular-kinetic theory of heat <span class="citation">[25,38]</span>.</p>
<p>In 1923, the Wiener process was coined in honor of Norbert Wiener mathematical proof of existence of the Brownian motion and stating its properties.<a href="#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a></p>

<!-- \ref{wiener} -->
<!-- \@ref(fig:wiener) -->
<div class="figure" style="text-align: center"><span id="fig:wiener"></span>
<img src="thesis_files/figure-html/wiener-1.png" alt="A Wiener process trajectory path example \label{wiener}" width="480" />
<p class="caption">
Figure 1.1: A Wiener process trajectory path example 
</p>
</div>
<div id="corr" class="section level4">
<h4><span class="header-section-number">1.1.2.1</span> Correlated Brownian Motions</h4>
<p>Two independent Brownian motions that are correlated can describe a new process <span class="math inline">\(Z_t\)</span>. Let <span class="math inline">\(W_1\)</span> and <span class="math inline">\(W_2\)</span> be these two <em>independent</em> Brownian motions and let <span class="math inline">\(-1 \leq \rho \leq 1\)</span> be a given number. For <span class="math inline">\(0 \leq t \leq T\)</span> define the new process <span class="math inline">\(Z_t\)</span> as <span class="citation">[38]</span>:</p>
<span class="math display">\[\begin{align}
\label{eq:corr_brow}
Z_t = \rho W_{1,t} + \sqrt{1-\rho^2}W_{2,t}
\end{align}\]</span>
<p>This equation is a linear combination of independent normals at each timestep <span class="math inline">\(t\)</span>, so <span class="math inline">\(Z_t\)</span> is normally distributed. It is proven that <span class="math inline">\(Z\)</span> is a Brownian motion and that <span class="math inline">\(Z\)</span> and <span class="math inline">\(W_{1,t}\)</span> have correlation <span class="math inline">\(\rho\)</span> <span class="citation">[38]</span>.</p>
</div>
</div>
<div id="itos-integral" class="section level3">
<h3><span class="header-section-number">1.1.3</span> Itô’s Integral</h3>
<p>Formally, the SDE presented in equation <a href="#eq:sde1">(<strong>??</strong>)</a> only exists because we can rewrite it in the form <span class="citation">[10,21,22,32,35,36]</span>:</p>
<span class="math display">\[\begin{align} 
\label{eq:sde2}
x_t &amp;= x_0 + \int_{0}^{t}{f(s, x_s)ds} + \int_{0}^{t}{g(s, x_s)dW_s}
\end{align}\]</span>
<p>for some <span class="math inline">\(f(s, x_s)\)</span>, <span class="math inline">\(g(s, x_s)\)</span> and <span class="math inline">\(s \in [0,t]\)</span>.</p>
<div id="section" class="section level21">
<p><span class="header-section-number">1.1.3.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1</span> </p>
<p>The Itô integral can, as the Riemann integral, be approximated by a finite sum. Also, it has a definition as a certain limit. Itô’s lemma <a href="#itolemma"><strong>??</strong></a> plays the same role as the fundamental theorem of calculus in allowing to evaluate integrals. It is the formal definition and presents an extra term not encountered in the conventional calculus theorem that is due to the non-smoothness characteristics of Brownian motion paths. It is possible, though, to define the integral in a less rigorous way:</p>
<span class="math display">\[\begin{align}
Y_{\Delta t}(t) \approx \sum_{t_k &lt; t}{g(t_k)\Delta W_k}
\end{align}\]</span>
<p>with the usual notions <span class="math inline">\(t_k = k\Delta t\)</span>, and <span class="math inline">\(\Delta W_k = W(t_{k+1})-W(t_k)\)</span>. And in a more rigorous form, if the limit exists, then the Ito integral is:</p>
<span class="math display">\[\begin{align}
Y(t)  = \lim\limits_{\Delta t \to 0} Y_{\Delta t}(t)
\end{align}\]</span>
<p>It is essential that the <em>forward difference</em> is used rather than the backward difference, which would be wrong.</p>

<p>Equation <a href="#eq:ito">(<strong>??</strong>)</a> is the stochastic equivalent to the chain rule, also known as Itô’s formula or Itô’s chain rule. The proof to this theorem is based on the Taylor expansion of the function <span class="math inline">\(f(S_t, t)\)</span> <span class="citation">[10,36]</span>. For practical use you should write out a second-order Taylor expansion for the function to be analyzed and apply the Table <a href="lt-review.html#tab:box-calc">1.1</a> multiplication table <span class="citation">[38]</span>.</p>
<table>
<caption><span id="tab:box-calc">Table 1.1: </span>Box calculus</caption>
<thead>
<tr class="header">
<th></th>
<th align="left"><span class="math inline">\(dt\)</span></th>
<th align="right"><span class="math inline">\(dW_t\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(dt\)</span></td>
<td align="left">0</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td><span class="math inline">\(dW_t\)</span></td>
<td align="left">0</td>
<td align="right"><span class="math inline">\(dt\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="itos-integral-properties" class="section level4">
<h4><span class="header-section-number">1.1.3.1</span> Itô’s Integral Properties</h4>
<p>Let <span class="math inline">\(f\)</span>, <span class="math inline">\(g\)</span> <span class="math inline">\(\in\)</span> <span class="math inline">\(\mathcal{V}\)</span> and let <span class="math inline">\(0 \leq t_0 &lt; u &lt; T\)</span>. Then</p>

</div>
</div>
</div>
<div id="black-scholes-model" class="section level2">
<h2><span class="header-section-number">1.2</span> Black-Scholes Model</h2>
<div id="basics" class="section level3">
<h3><span class="header-section-number">1.2.1</span> Basics</h3>
<p>The Black-Scholes (B-S) model arises from the need to price european options in the derivative markets. Derivatives are financial instruments traded in the market, stock exchange or over-the-counter (OTC) market, whose values depend on the values of an underlying asset. <span class="citation">[3,33,40]</span></p>
<ul>
<li><p>A call option is a derivative that gives its bearer the right, but not the obligation, to purchase a specific asset by a fixed price before or on a given date.</p></li>
<li><p>A put option is a derivative that gives its bearer the right, but not the obligation, to sell a specific asset by a fixed price before or on a given date.</p></li>
</ul>
<p>The trading price of the option is called the option <em>premium</em> and the asset from which the option derives is called the <em>underlying asset</em>. This asset may be interest rates, exchange rates, stock exchanges indices, commodities or stocks. The fixed price in contract in which the underlying asset might to be bought or sold is the <em>strick price</em>. The option expiration date is called the <em>maturity</em>. <span class="citation">[3,33]</span></p>
<p>There are two major different option types: European and American. The difference between these two is that the bearer of the first may exercise it only at the end of its life, at its maturity while the latter can be exercised at any given time until its maturity. <span class="citation">[3,29]</span></p>
<!-- \begin{definition}{(Implicit volatility)}  -->
<!-- Given all the option's parameters in a precification model and its market price, the option's volatility is called the \textit{implicit volatility}. -->
<!-- \end{definition} -->

<div id="gbm" class="section level4">
<h4><span class="header-section-number">1.2.1.1</span> Geometric Brownian Motion</h4>
<p>A stochastic process <span class="math inline">\(S_t\)</span> is a Geometric Brownian Motion<a href="#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> if it is described by the solution of the following stochastic differential equation <span class="citation">[36–38]</span>.</p>
<span class="math display">\[\begin{align}
dS_t = \mu S_t dt + \sigma S_t dW_t
\end{align}\]</span>
<p>for given constants <span class="math inline">\(\mu \in {\rm I\!R}\)</span> and <span class="math inline">\(\sigma &gt; 0\)</span>. Also, the assumed initial value is positive, <span class="math inline">\(S_0 &gt;0\)</span>.</p>
<p>Figure <a href="lt-review.html#fig:gbm">1.2</a> shows the GBM,<a href="#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> which is quite often applied to model the dynamics of some financial assets because of its properties <span class="citation">[19]</span>. Equation <a href="#eq:sde3">(<strong>??</strong>)</a> shows the formula to generate a GBM and we provide proof of this solution in appendix <a href="bsformula.html#bsformula">A</a><a href="#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a></p>
<span class="math display">\[\begin{align} \label{eq:sde3}
S_t = S_0 \times exp{\left( \left( \mu - \frac{\sigma^2}{2} \right) t + \sigma W_t \right)}, \;\; t &gt; 0
\end{align}\]</span>
<div class="figure" style="text-align: center"><span id="fig:gbm"></span>
<img src="thesis_files/figure-html/gbm-1.png" alt="A GBM trajectory path example \label{gbm}" width="480" />
<p class="caption">
Figure 1.2: A GBM trajectory path example 
</p>
</div>
</div>
</div>
<div id="the-model" class="section level3">
<h3><span class="header-section-number">1.2.2</span> The model</h3>
<p>The Black-Scholes model provides analytical solution to the price of a European call at time <span class="math inline">\(t\)</span> and can be described as follows <span class="citation">[3,16,40]</span>:</p>
<span class="math display">\[\begin{align}
C(S_{t},t)&amp;=N(d_{1})S_{t}-N(d_{2})Ke^{-r(T-t)}\\[10pt]
d_{1}&amp;={\frac {1}{\sigma {\sqrt {T-t}}}}\left[\ln \left({\frac {S_{t}}{K}}\right)+\left(r+{\frac {\sigma ^{2}}{2}}\right)(T-t)\right]\\[10pt]
d_{2}&amp;=d_{1}-\sigma {\sqrt {T-t}}
\end{align}\]</span>
<p>Where:</p>
<ul>
<li><span class="math inline">\(S_{t}\)</span> is the spot price of the underlying asset at time <span class="math inline">\(t\)</span></li>
<li><span class="math inline">\(r\)</span> is the risk free rate (generally an annual rate)</li>
<li><span class="math inline">\(\sigma\)</span> is the volatility of returns of the underlying asset </li>
<li><span class="math inline">\(N(\cdot )\)</span> is the cumulative distribution function of the standard Gaussian distribution</li>
<li><span class="math inline">\(K\)</span> is the strike price</li>
<li><span class="math inline">\(T-t\)</span> is the time to maturity</li>
</ul>
<p>Also, the stock price path is a Geometric Brownian Motion as previously stated, and is under the risk-neutral measure with the following dynamics <span class="citation">[14,16]</span>:</p>
<span class="math display">\[\begin{align}
dS_{t} = (r-q)S_td_t+\sigma S_t dW_t
\end{align}\]</span>
<p>Where <span class="math inline">\(dW_t\)</span> is a Wiener process <span class="citation">[3,14]</span>, <span class="math inline">\(r\)</span> is the risk free rate and <span class="math inline">\(q\)</span> is the dividend yield and <span class="math inline">\(t\)</span> denotes the current point in time.</p>
</div>
<div id="limitations" class="section level3">
<h3><span class="header-section-number">1.2.3</span> Limitations</h3>
<p>Although the Black-Scholes is very popular and the <em>de facto</em> standard in the market there are implications to the B-S model assumptions that affect the results and that are unrealistic. The main assumption that does not hold up is the deterministic (constant) volatility, that can more accurately be described as a stochastic process since we observe that small moves usually are followed by small moves and large moves by large moves. <span class="citation">[16,40]</span></p>
<p>Other assumptions that are critical to the B-S model and are not always observed in practice refer to the asset’s continuity through time (no jumps), being allowed to perform continuous hedge without transactions costs and normal (Gaussian) returns.</p>
<p>Most models focus on the volatility problem because transaction costs often translate to rises in volatility and fat-tails (abnormal) returns can be simulated by stochastic volatility and market or volatility jumps.</p>
<!-- Out of all the parameters that the call price depends on in the Black Scholes -->
<!-- model, the volatility is the only one that is unobservable, but we can let the -->
<!-- market of liquid derivatives decide which volatility has to be plugged in the -->
<!-- model. The calibrated σ* is the one that fits best the model prices to the observed -->
<!-- market prices, by minimizing the sum of square errors: -->
<!-- σ ∗ = arg q    min -->
<!-- 2,o -->
<!-- C mn S " , K 2 , σ, T o − C p S", K 2 , T o -->
<!-- . -->
<!-- Knowing S, K, T, r, q and the quoted option call value it is possible to extract the -->
<!-- implied volatility. -->
<!-- [@tong2012option] -->
<!-- Using Black-Scholes option pricing model, the price of a call option is the function of -->
<!-- the spot (current) price S(0), interest rate r, the strike K, the constant volatility σ -->
<!-- and the maturity T . Except for the volatility σ, all the other variables are observable. -->
<!-- Since the quoted option price C obs is observable, using the Black-Scholes formula we -->
<!-- can therefore calculate or imply the volatility that is consistent with the quoted his- -->
<!-- torical option prices and observed variables. We can therefore define implied volatility -->
<!-- σimpl by -->
<!-- C BS (0; r, K, T, σimpl , S(0)) = C obs -->
<!-- where C BS is the option price calculated by the Black-Scholes formula (equation -->
<!-- (3.3.9)). Implied volatility surfaces are graphs plotting σimpl for each call option’s -->
<!-- strike K and expiration T . Theoretically, options whose underlying is governed by -->
<!-- the geometric Brownian motion should have a flat implied volatility surface, since -->
<!-- volatility is a constant. -->
<!-- [@yang2013valuing] -->
<!-- Volatility is a measure for variation of price of a stock over time. Stochastic volatility is described as -->
<!-- processes in which the return variation dynamics include an unobservable shock that cannot be predicted -->
<!-- using current available information. Stochastic volatility models, which let the volatility follow Brownian -->
<!-- motion, make the option price much better adapted to the realities of the market. -->
</div>
</div>
<div id="stochastic-volatility-models" class="section level2">
<h2><span class="header-section-number">1.3</span> Stochastic Volatility models</h2>
<p>Introducing stochastic volatility to models brings complexity, but enables modeling some features observed in reality that are crucial, like the randomic market volatility effects, skewness (market returns are more realistically modeled) and volatility smile<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a> (see Figure <a href="lt-review.html#fig:smile">1.3</a>). This kind of model is applied highly succesfully in foreign exchange and credit markets.</p>

<p>Furthermore, stochastic volatility models use statistical methods as foundations to price and forecast options’ behaviors and the underlying’s security volatility is arbitrary. The Heston, the <span class="math inline">\(3/2\)</span> and other models, like the GARCH<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> and SABR,<a href="#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> are considered standard smile models.</p>
<div class="figure" style="text-align: center"><span id="fig:smile"></span>
<img src="thesis_files/figure-html/smile-1.png" alt="Volatility Smile \label{smile}" width="480" />
<p class="caption">
Figure 1.3: Volatility Smile 
</p>
</div>
<div id="cir" class="section level3">
<h3><span class="header-section-number">1.3.1</span> Cox-Ingersoll-Ross model</h3>
<p>The Cox-Ingersoll-Ross (CIR) model is a well-known short-rate model that describes the interest rate movements driven by one source of market risk. The dynamics are described as follows<span class="citation">[8,17]</span>:</p>
<span class="math display">\[\begin{align}
\label{eq:cir}
dr_t &amp;= k(\theta - r_t)dt + \sigma \sqrt{r_t} dB_t
\end{align}\]</span>
<p>Where, <span class="math inline">\(r_t\)</span> is the short rate interest described by parameters <span class="math inline">\(\kappa\)</span> the speed of mean reversion, <span class="math inline">\(\theta\)</span> the long-run mean variance and <span class="math inline">\(\sigma\)</span> the volatility of the variance process.</p>
<p>This model has been widely used to describe the dynamics of the short rate interest because it has some fundamental features like intuitive parametrization, nonnegativity and pricing formulas. Besides, it takes account of anticipations, risk aversion, investment alternatives and preferences about consumption timing and allows for detailed predictions about how changes in a wide range of underlying variables affect the term structure<span class="citation">[8]</span>. Furthermore, this equation constitutes one of the two Heston model equations with the volatility taking the short rate interest place.</p>
</div>
<div id="hes1" class="section level3">
<h3><span class="header-section-number">1.3.2</span> Heston Model</h3>
<p>Heston model was introduced in 1993 by Steven Heston to solve the deterministic volatility problems. It was designed to analize bond and currency options and it introduced the following equations, which represent the dynamics of the stock price and the variance processes under the risk-neutral measure <span class="citation">[15,17]</span>:</p>
<span class="math display">\[\begin{align}
\label{eq:heston}
dS_t &amp;= \mu S_t dt + \sqrt{V_t} S_t dW^*_t \\
dV_t &amp;=  \kappa (\theta - V_t)dt + \sigma \sqrt{V_t} dB_t
\label{eq:hesvar}
\end{align}\]</span>
<p>The second equation, as described in Section <a href="lt-review.html#cir">1.3.1</a>, is the CIR model equation. The first equation states the asset price process. <span class="math inline">\(\mu\)</span> is the asset’s rate of return, <span class="math inline">\(dW_{t,1}\)</span> and <span class="math inline">\(dW_{t,2}\)</span> are two correlated wiener processes with correlation coefficient of <span class="math inline">\(\rho\)</span>.</p>
</div>
<div id="other-models" class="section level3">
<h3><span class="header-section-number">1.3.3</span> Other Models</h3>
<div id="ornstein-uhlenbeck" class="section level4">
<h4><span class="header-section-number">1.3.3.1</span> Ornstein-Uhlenbeck</h4>
<p>The Ornstein-Uhlenbeck is the earliest recorded SDE. Named after Leonard Ornstein and George Eugene Uhlenbeck, it is a stochastic process that describes the acceleration of a pollen particle in a liquid subject to bombardments by molecules <span class="citation">[38]</span>. As we can observe in equation <a href="#eq:oueq">(<strong>??</strong>)</a>, <span class="math inline">\(x_t\)</span> represents the one dimension velocity of the particle, thus <span class="math inline">\(dx_t\)</span> is the <em>change</em> in velocity, in other words, its acceleration. The <span class="math inline">\(- \theta x_t\)</span> component slows down the acceleration and is to be understood as frictional force. Besides, we add a noise <span class="math inline">\(W_t\)</span> with intensity <span class="math inline">\(\sigma\)</span> that models the random bombardment by the molecules.</p>
<span class="math display">\[\begin{align} 
\label{eq:oueq}
&amp;d x_t = - \theta x_t dt + \sigma d W_t
\end{align}\]</span>
<p>With <span class="math inline">\(\theta\)</span> and <span class="math inline">\(\sigma\)</span> being positive constants. Expressing in terms of <span class="math inline">\(x_t\)</span> we get:</p>
<span class="math display">\[\begin{align}
x_t = e^{-\theta t} \times \left[ x_0  + \sigma \int_{t=0}^{T} e^{\theta t} d W_s \right] \,.
\end{align}\]</span>
</div>
<div id="langevin" class="section level4">
<h4><span class="header-section-number">1.3.3.2</span> Langevin</h4>
<p>The Langevin equation describes a system that consists of the molecular bombardment of a speck of dust on a water surface. We know that the intensity of the bombardement does not depend on the state variables <span class="citation">[12,26]</span>.</p>
<span class="math display">\[\begin{align}
m \frac{dv}{dt} = -\zeta v + \delta F (t) 
\end{align}\]</span>
<p><span class="math inline">\(m\)</span> is the mass of the particle, <span class="math inline">\(v\)</span> it’s velocity, <span class="math inline">\(-\zeta v\)</span> is the frictional force, which is proportional to the velocity, and <span class="math inline">\(\delta F (t)\)</span> is a <em>fluctuating</em> force (random) to the frictional force.</p>
</div>
</div>
</div>
<div id="numerical-methods" class="section level2">
<h2><span class="header-section-number">1.4</span> Numerical Methods</h2>
<p>Numerical methods are tools that are often applied to solve stochastic differential equations because most of these do not have explicit solution. This means that we are not able to solve these equations using symbolic computation. Although we are unable to find an analitical solution, when facing real problems, the approximation given by a numerical method is often sufficient. Alongside the analytical issue, the need to calculate the SDE’s trajectory through time is the main reason why studying numerical methods is so important. An implementation of a numerical method is called a numerical algorithm.</p>
<p>We will simulate sample paths of time discrete approximations implemented in the R programming language <span class="citation">[30]</span> that we base on a finite discretization of a time interval <span class="math inline">\([t_0, T]\)</span>. We shall generate approximate values of the sample path for each step contained in the discretized interval <span class="citation">[26]</span>.</p>
<p>In the fixed step methods, the distance between two contiguous points is the distance <span class="math inline">\(d_i = t_i - t_{i-1} = \frac{T-t_0}{N} \;\;\; \forall i \mid 1 \leq i \leq N \in \mathbb{N}\)</span>. <span class="math inline">\(N\)</span> being the time interval partition number.</p>
<p>According to Kloeden <span class="citation">[26]</span>, in the stochastic realm, simulated sample paths can be statistically analysed to find how good an approximation is compared to an exact solution. Moreover, the computational costs such as time and memory increases polynomially with the problem’s dimension, which is good, and it is possible to apply variance reduction methods that allow a considerable decrease in the required sample size.</p>
<div id="convergence" class="section level3">
<h3><span class="header-section-number">1.4.1</span> Convergence</h3>
<p>As soon as we talk about numerical methods we are required to approach the topic of approximations and how to handle them. Methods efficiency receive the name of <em>convergence order</em>. In the SDE domain there are two main methods of convergency, that are classified according to their criteria. Firstly, we present the <em>strong order of convergence</em>. A method is said to have strong convergence <span class="math inline">\(\delta\)</span> to <span class="math inline">\(Y\)</span> if a time discretized <span class="math inline">\(Y_{\delta}\)</span> of a continous-time process <span class="math inline">\(Y\)</span>, with <span class="math inline">\(\delta\)</span> being the maximum time increment of the discretization, and for any fixed time horizon <span class="math inline">\(T\)</span> holds true that <span class="citation">[19]</span>:</p>
<span class="math display">\[\begin{align*}
\mathbb{E} \mid Y_{\delta}(T) - Y(T) \mid \leq C \delta^{\gamma}, \,\,\, \forall \delta &lt; \delta_0
\end{align*}\]</span>
<p>with <span class="math inline">\(\delta_0 &gt; 0\)</span> and <span class="math inline">\(\mathcal{C}\)</span> a constant not depending on <span class="math inline">\(\delta\)</span>. Strong convergence addresses the problem of solutions’ trajectories. For specific conditions, the Euler method has strong convergence order <span class="math inline">\(\gamma = \frac{1}{2}\)</span>. Furthermore, there is the <em>weak order of convergence</em>. The weak convergence</p>
<span class="math display">\[\begin{align*}
\mid  \mathbb{E}p(Y_n) - \mathbb{E}p(Y(\tau)) \mid \leq C \Delta t^{\gamma}
\end{align*}\]</span>
<p>Strong and weak convergence are not mutually exclusive <span class="citation">[19]</span>. That means that a method with a given strong order of convergence might have a higher weak order of convergence too. This is the case for the Euler scheme, with a strong order of convergence of <span class="math inline">\(1/2\)</span> and a weak order of <span class="math inline">\(1\)</span> (under some conditions). For a more detailed and rigorous explanation of convergence we recommend consulting <span class="citation">[18]</span>.</p>
<p>It is worth noting that, altough schemes have a given convergency order, it is not unusual that they behave better than their order for some SDEs specifications.</p>
</div>
<div id="discretization" class="section level3">
<h3><span class="header-section-number">1.4.2</span> Discretization</h3>
<p>We know that convergence is an important feature to a numerical method and studies have found not all time discrete possible approximations of an SDE converge in a useful sense to the solution process as the step size adopted tends toward zero <span class="citation">[6,7]</span>. Moreover, particularly for SDEs, some of the more rapidly convergent methods available for ordinary differential equations (ODE) do not work, such as higher order Runge-Kutta methods.<a href="#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a></p>
<p>One of the methods that do work for ODEs and SDEs is the Euler method, named after the Swiss mathematician Leonhard Euler. Figure <a href="lt-review.html#fig:euler">1.4</a> shows an example of an implementation for the Newton’s cooling law with timestep of 2 seconds compared to its analytical solution. This method (<em>a.k.a.</em> forward Euler method) is a first-order numerical procedure. It is the most basic explicit method<a href="#fn9" class="footnoteRef" id="fnref9"><sup>9</sup></a> for numerical integration.</p>
<div class="figure" style="text-align: center"><span id="fig:euler"></span>
<img src="thesis_files/figure-html/euler-1.png" alt="Analytical x Euler solutions \label{euler}" width="480" />
<p class="caption">
Figure 1.4: Analytical x Euler solutions 
</p>
</div>
<p>The method is first-order, as stated above, this means that the error in each step is a proportion of the square of the step size. Also, the global error at a given time is a function of the step size. We proceed to apply the Euler method to SDEs. Consider the equation:</p>
<span class="math display">\[\begin{align}
dS_t &amp;= \mu(S_t,t) dt + \sigma(S_t,t) dW_t
\end{align}\]</span>
<p><span class="math inline">\(dW_t\)</span> is the Brownian motion, <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are functions depending on <span class="math inline">\(S_t\)</span> and <span class="math inline">\(t\)</span>, over an interval <span class="math inline">\([0,T]\)</span>, and we want to discretize it as <span class="math inline">\(0 = t_1 &lt; t2 &lt; \cdots &lt; t_m = T\)</span> with increments equally spaced <span class="math inline">\(d_t\)</span>.</p>
<p>Integrating it from <span class="math inline">\(t\)</span> to <span class="math inline">\(dt\)</span> we have the starting point for our (and any) discretization scheme:</p>
<span class="math display">\[\begin{align}
\label{eq:disc1}
S_{t+dt} &amp;= S_t + \int_{t}^{dt}{\mu(S_u,u)}du + \int_{t}^{dt}{\sigma(S_u,u)} dW_u
\end{align}\]</span>
<p>To use the Euler discretization is the equivalent of approximating integrals using the left-point rule, we then have:</p>
<span class="math display">\[\begin{align*}
 \int_{t}^{t+dt}{\mu(S_u,u)} dW_u &amp;\approx \mu(S_t,t) \int_{t}^{t+dt}dW_u\\
&amp;= \mu(S_t,t) (W_{t+dt} - W_t)  \\
 \int_{t}^{t+dt}{\sigma(S_u,u)} dW_u &amp;\approx \sigma(S_t,t) \int_{t}^{t+dt}dW_u\\
&amp;= \sigma(S_t,t) (W_{t+dt} - W_t)  \\
&amp;= \sigma(S_t,t) \sqrt{dt} Z
\end{align*}\]</span>
<p><span class="math inline">\(W_{t+dt}-W_t\)</span> and <span class="math inline">\(\sqrt{dt}Z\)</span> have identical distribution, <span class="math inline">\(Z\)</span> being a standard gaussian variable. The Euler discretization of equation <a href="#eq:disc1">(<strong>??</strong>)</a> is then:</p>
<span class="math display">\[\begin{align}
\label{eq:disc2}
S_{t+dt} &amp;= S_t + \mu(S_t,t)dt + \sigma(S_t,t)\sqrt{dt}Z
\end{align}\]</span>
<div id="euler-method---heston-model" class="section level4">
<h4><span class="header-section-number">1.4.2.1</span> Euler method - Heston model</h4>
<p>We now proceed to apply the method to our model of interest. We retake the equations <a href="#eq:heston">(<strong>??</strong>)</a> and <a href="#eq:hesvar">(<strong>??</strong>)</a>. We begin showing how to discretize the latter <span class="citation">[18,19]</span>:</p>
<span class="math display">\[\begin{align}
\label{eq:hesvareuler}
V_{t+dt} = V_t+ \int_{t}^{t+dt}{\kappa (\theta - V_u) du} + \int_{t}^{t+dt}{\sigma \sqrt{V_u} dB_u}
\end{align}\]</span>
<p>Which discretized turns out as:</p>
<span class="math display">\[\begin{align*}
 \int_{t}^{t+dt}{\kappa (\theta - V_u)} du &amp;\approx \kappa (\theta - V_t) dt\\
 \int_{t}^{t+dt}{\sigma \sqrt{V_u}} dB_t &amp;\approx \sigma \sqrt{V_t} (W_{t+dt}-W_t)\\
&amp;= \sigma \sqrt{V_t dt} Z_v
\end{align*}\]</span>
<p>And leaves us with:</p>
<span class="math display">\[\begin{align}
V_{t+dt} = V_t + \kappa (\theta - V_t) dt + \sigma \sqrt{V_t dt} Z_v
\end{align}\]</span>
<p><span class="math inline">\(Z_v\)</span> is a standard normal variable. To avoid problems with negative values in <span class="math inline">\(\sqrt{V_t}\)</span> we apply the <em>full truncation</em> scheme, which substitutes <span class="math inline">\(V_t\)</span> with <span class="math inline">\(V_t^+ = max(0, V_t)\)</span>.<a href="#fn10" class="footnoteRef" id="fnref10"><sup>10</sup></a></p>
<p>For the <span class="math inline">\(S_t\)</span> SDE we proceed similarly:</p>
<span class="math display">\[\begin{align}
\label{eq:heseuler}
S_{t+dt} = S_t+ \mu \int_{t}^{t+dt}{ S_u du} + \int_{t}^{t+dt}{\sqrt{V_u} S_u dW_u}
\end{align}\]</span>
<p>Discretizing we have:</p>
<span class="math display">\[\begin{align*}
 \int_{t}^{t+dt}{S_u} du &amp;\approx S_t dt\\
 \int_{t}^{t+dt}{\sqrt{V_u} S_u} dW_u &amp;\approx \sqrt{V_t} S_t (W_{t+dt}-W_t)\\
&amp;= \sqrt{V_t dt} S_t Z_s
\end{align*}\]</span>
<p><span class="math inline">\(Z_s\)</span> is a standard normal variable with correlation <span class="math inline">\(\rho\)</span> with <span class="math inline">\(Z_v\)</span>. We have:</p>
<span class="math display">\[\begin{align}
S_{t+dt} = S_t + \mu S_t dt + \sqrt{V_t dt} S_t Z_s
\end{align}\]</span>
</div>
</div>
<div id="stability" class="section level3">
<h3><span class="header-section-number">1.4.3</span> Stability</h3>
<p>Most differential equations, deterministic or stochastic, cannot be solved explicitly <span class="citation">[26]</span>. Hence, stability studies begin with computers and is associated with numerical methods and approximations. Convergent methods were resulting in bigger errors than what was expected that could not be only due to discretization error. Eventually, scientists discovered that this unexpected problem was caused by accumulation of successive truncation errors. Figure <a href="lt-review.html#fig:stab">1.5</a> retakes the cooling example previously approached to show instability due to an increase in size of the timestep and extending to <span class="math inline">\(600\)</span> seconds.</p>
<div class="figure" style="text-align: center"><span id="fig:stab"></span>
<img src="thesis_files/figure-html/stab-1.png" alt="Euler's stability whith different timesteps \label{stab}" width="480" />
<p class="caption">
Figure 1.5: Euler’s stability whith different timesteps 
</p>
</div>
<p>We know that binary machines like computers are not able to represent all the real numbers, but only a subset of them. Thus, solving these errors is not straightforward since it’s not possible to eliminate <em>all</em> truncation error when using a computer and dealing with numerical solutions. When faced to an incorrect (not acceptable) solution, we have to evaluate and distinguish between two distinct situations:</p>

<p>Examples of these two classes of problem can be found in <span class="citation">[15]</span>.</p>
<p>Stiff equations appear very often in mathematical problems and refer to differential equations for which a numerical methods might be unstable for not small enough stepsizes <span class="citation">[20]</span>. A differential equation of the form <span class="math inline">\(y&#39; = f(t,y)\)</span>, if its exact solution <span class="math inline">\(y(t)\)</span> includes a term that decays exponentially to zero as <span class="math inline">\(t\)</span> increases, but whose derivatives are greater in magnitude than the term itself. In other words, if it requires a significant depression of the stepsize to avoid stability lost. This is a loose definition but, since we are dealing with numerical methods a proper mathematical definition isn’t required. Tipically, these equations are of the form <span class="math inline">\(e^{-ct}\)</span>, where <span class="math inline">\(c\)</span> is a large positive constant <span class="citation">[5]</span>. A practical example of the stiff behavior is the following differential equation <span class="citation">[28]</span>:</p>
<span class="math display">\[\begin{align*}
y&#39; = -100y, \,\,\,\,\,\, t &gt; 0, \,\,\,\,\,\, y_0 = 1
\end{align*}\]</span>
<p>Whose exact solution is <span class="math inline">\(y_t = e^{-100 t}\)</span> and goes to zero as <span class="math inline">\(t\)</span> increases. Applying Euler’s method to this equation with <span class="math inline">\(h=0.1\)</span> we stumble in the following equation</p>
<span class="math display">\[\begin{align*}
y_{n+1} = y_{n} - 100 h y_{n} = -9y_{n}
\end{align*}\]</span>
<p>which is wrong, since it yields an exponencially growing solution <span class="math inline">\(y_n = (-9)^n\)</span>. On the other hand, if our timestep is smaller <span class="math inline">\(h = 10^{-3}\)</span>, our solution using Euler’s method becomes <span class="math inline">\(y_n = (0.9)^n\)</span>. This solution leads to an accurate behavior regarding the exact solution, it rapidily decays to zero.</p>
<p>Sometimes, it is interesting to rank differential equations that are more or less stiff. Thus, people compute the quotient of the largest and the smallest eigenvalues of a linear system. They call it the equations’  and, usually the bigger the stiffness ratio, the more likely is to be stiff <span class="citation">[20]</span>.</p>
<div id="stability-domain" class="section level4">
<h4><span class="header-section-number">1.4.3.1</span> Stability Domain</h4>
<p>Let’s take the equation:</p>
<span class="math display">\[\begin{align}
y&#39; = \lambda y,  \,\,\,\,\,\, t \geq 0, \,\,\,\,\,\,\,\,\,\,\,\,\,\, y_0 = 1
\end{align}\]</span>
<p>where <span class="math inline">\(\lambda \in \mathbb{C}\)</span> or in other terms <span class="math inline">\(\lambda = \lambda_r + i \lambda_i\)</span> and whose solution is <span class="math inline">\(y+t = e^{\lambda t}\)</span>. We can rewrite this equation as a system:</p>
<span class="math display">\[\begin{align}
\frac{d}{dt} \begin{bmatrix} y^1 \\ y^2 \end{bmatrix} = 
\begin{pmatrix} 
\lambda_r &amp; - \lambda_i \\
\lambda_i &amp; - \lambda_r 
\end{pmatrix}
\begin{bmatrix} y^1 \\ y^2 \end{bmatrix}
\end{align}\]</span>
<p>The <span class="math inline">\(\lim_{t \to \infty} y_t = 0\)</span> if and only if <span class="math inline">\(\mathbb{R} \lambda &lt; 0\)</span>. The <em>linear stability domain</em> <span class="math inline">\(\mathcal{D}\)</span> is defined as the set of all numbers <span class="math inline">\(\Delta \lambda \in mathbb{C}\)</span> such that <span class="math inline">\(\lim_{n \to \infty y+n = 0}\)</span>, with <span class="math inline">\(\Delta &gt; 0\)</span> being the stepsize. Or, as stated in Kloeden <span class="citation">[26]</span>, the suitable values of the stepsize are expressed in terms of <em>region of absolute stability</em>, consisting of the complex numbers <span class="math inline">\(\lambda \Delta\)</span> for which an error in <span class="math inline">\(y_0\)</span> at <span class="math inline">\(t_0\)</span> will not grow in subsequent iterations of the method.</p>
<p>Without entering all the details, for these we recommend <span class="citation">[20,26,28]</span>, the euler’s stability domain is:</p>
<span class="math display">\[\begin{align*}
\mathcal{D}_{Euler} = z \in \mathbb{C} : \mid 1 + z \mid &lt; 1
\end{align*}\]</span>
<p>which represents the interior of a complex disc of unit radius and centre <span class="math inline">\(z = -1\)</span> as can be seen in Figure <a href="#stab2"><strong>??</strong></a>, on the left. The right side of the Figure <a href="#stab2"><strong>??</strong></a> shows the stability region called A-stability.<a href="#fn11" class="footnoteRef" id="fnref11"><sup>11</sup></a> If a method is A-stable, the stepsize <span class="math inline">\(\Delta\)</span> is only constraint by accuracy</p>
<!-- # ```{r stab_domain, echo = FALSE, eval=TRUE, message=FALSE, fig.height=5, fig.width = 5, fig.align='center'} -->
<!-- # knitr::include_graphics("figure/stab_domain.pdf") -->
<!-- # ``` -->
<div class="figure" style="text-align: left"><span id="fig:stab2"></span>
<img src="thesis_files/figure-html/stab2-1.png" alt="Stability domains \label{stab2}" width="561.6" />
<p class="caption">
Figure 1.6: Stability domains 
</p>
</div>
<p>Thereby, we claim that stability method study is an important topic, since it enables achieving solutions that are good to stiff equations without having to overly reduce our timesteps which can be very computationally costly.</p>
<!-- ### -->
<!-- [@gilli_numerical_2011] -->
<!--   The precision for finite difference methods depends, among other things, on -->
<!--   the number of time and space steps. These issues are known as the problem -->
<!--   of stability that is caused by an ill-conditioned linear system. We will not -->
<!--   discuss this problem in detail but simply give some intuition. We have to -->
<!--   be aware that increasing the number of space steps increases the size of the -->
<!--   linear system, and the number of time steps defines how often the linear -->
<!--   system has to be solved. Also, the parameters like volatility  and risk-free -->
<!--   rate r influence the conditioning of the linear system. -->
<!--   [@gilli_numerical_2011] -->
<!--   In Section 2.1, it has been shown that binary machines can represent only a -->
<!--   subset of the real numbers, introducing rounding errors that may seriously -->
<!--   affect the precision of the numerical solution. If the “quality” of a solution -->
<!--   is not acceptable, it is important to distinguish between the following two -->
<!--   situations: -->
<!--   i. Rounding errors are considerably amplified by the algorithm. This -->
<!--   situation is called numerical instability. -->
<!--   ii. Small perturbations of data generate large changes in the solution. This -->
<!--   is termed an ill-conditioned (or sensitive) problem. -->
<!--   In the following we give illustrations of numerical instability and of an -->
<!--   ill-conditioned problem. -->
<!-- ### -->
<div id="section-1" class="section level39">
<p><span class="header-section-number">1.4.3.1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.1</span> </p>
<!-- * Model -->
<!-- It's easy to create a list.  It can be unordered like -->
<!-- * Item 1 -->
<!-- * Item 2 -->
<!-- or it can be ordered like -->
<!-- 1. Item 1 -->
<!-- 4. Item 2 -->
<!-- Notice that I intentionally mislabeled Item 2 as number 4.  _Markdown_ automatically figures this out!  You can put any numbers in the list and it will create the list.  Check it out below. -->
<!-- To create a sublist, just indent the values a bit (at least four spaces or a tab).  (Here's one case where indentation is key!) -->
<!-- 1. Item 1 -->
<!-- 1. Item 2 -->
<!-- 1. Item 3 -->
<!--     - Item 3a -->
<!--     - Item 3b -->
<!-- ## Line breaks -->
<!-- Make sure to add white space between lines if you'd like to start a new paragraph.  Look at what happens below in the outputted document if you don't: -->
<!-- Here is the first sentence.  Here is another sentence.  Here is the last sentence to end the paragraph. -->
<!-- This should be a new paragraph. -->
<!-- *Now for the correct way:* -->
<!-- Here is the first sentence.  Here is another sentence.  Here is the last sentence to end the paragraph. -->
<!-- This should be a new paragraph. -->
<!-- ## R chunks -->
<!-- When you click the **Knit** button above a document will be generated that includes both content as well as the output of any embedded **R** code chunks within the document. You can embed an **R** code chunk like this (`cars` is a built-in **R** dataset): -->
<!-- ```{r cars} -->
<!-- summary(cars) -->
<!-- ``` -->
<!-- ## Inline code -->
<!-- If you'd like to put the results of your analysis directly into your discussion, add inline code like this: -->
<!-- > The `cos` of $2 \pi$ is 1. -->
<!-- Another example would be the direct calculation of the standard deviation: -->
<!-- > The standard deviation of `speed` in `cars` is 5.2876444. -->
<!-- One last neat feature is the use of the `ifelse` conditional statement which can be used to output text depending on the result of an **R** calculation: -->
<!-- > The standard deviation is less than 6. -->
<!-- Note the use of `>` here, which signifies a quotation environment that will be indented. -->
<!-- As you see with `$2 \pi$` above, mathematics can be added by surrounding the mathematical text with dollar signs.  More examples of this are in [Mathematics and Science] if you uncomment the code in [Math]. -->
<!-- ## Including plots -->
<!-- You can also embed plots.  For example, here is a way to use the base **R** graphics package to produce a plot using the built-in `pressure` dataset: -->
<!-- ```{r pressure, echo=FALSE, cache=TRUE} -->
<!-- plot(pressure) -->
<!-- ``` -->
<!-- Note that the `echo=FALSE` parameter was added to the code chunk to prevent printing of the **R** code that generated the plot.  There are plenty of other ways to add chunk options.  More information is available at <http://yihui.name/knitr/options/>. -->
<!-- Another useful chunk option is the setting of `cache=TRUE` as you see here.  If document rendering becomes time consuming due to long computations or plots that are expensive to generate you can use knitr caching to improve performance.  Later in this file, you'll see a way to reference plots created in **R** or external figures. -->
<!-- ## Loading and exploring data -->
<!-- Included in this template is a file called `flights.csv`.  This file includes a subset of the larger dataset of information about all flights that departed from Seattle and Portland in 2014.  More information about this dataset and its **R** package is available at <http://github.com/ismayc/pnwflights14>.  This subset includes only Portland flights and only rows that were complete with no missing values.  Merges were also done with the `airports` and `airlines` data sets in the `pnwflights14` package to get more descriptive airport and airline names. -->
<!-- We can load in this data set using the following command: -->
<!-- ```{r load_data} -->
<!-- flights <- read.csv("data/flights.csv") -->
<!-- ``` -->
<!-- The data is now stored in the data frame called `flights` in **R**.  To get a better feel for the variables included in this dataset we can use a variety of functions.  Here we can see the dimensions (rows by columns) and also the names of the columns. -->
<!-- ```{r str} -->
<!-- dim(flights) -->
<!-- names(flights) -->
<!-- ``` -->
<!-- Another good idea is to take a look at the dataset in table form.  With this dataset having more than 50,000 rows, we won't explicitly show the results of the command here.  I recommend you enter the command into the Console **_after_** you have run the **R** chunks above to load the data into **R**. -->
<!-- ```{r view_flights, eval=FALSE} -->
<!-- View(flights) -->
<!-- ``` -->
<!-- While not required, it is highly recommended you use the `dplyr` package to manipulate and summarize your data set as needed.  It uses a syntax that is easy to understand using chaining operations.  Below I've created a few examples of using `dplyr` to get information about the Portland flights in 2014.  You will also see the use of the `ggplot2` package, which produces beautiful, high-quality academic visuals. -->
<!-- We begin by checking to ensure that needed packages are installed and then we load them into our current working environment: -->
<!-- ```{r load_pkgs, message=FALSE} -->
<!-- # List of packages required for this analysis -->
<!-- pkg <- c("dplyr", "ggplot2", "knitr", "bookdown", "devtools") -->
<!-- # Check if packages are not installed and assign the -->
<!-- # names of the packages not installed to the variable new.pkg -->
<!-- new.pkg <- pkg[!(pkg %in% installed.packages())] -->
<!-- # If there are any packages in the list that aren't installed, -->
<!-- # install them -->
<!-- if (length(new.pkg)) -->
<!--   install.packages(new.pkg, repos = "http://cran.rstudio.com") -->
<!-- # Load packages (thesisdown will load all of the packages as well) -->
<!-- library(thesisdown) -->
<!-- ``` -->
<!-- \clearpage -->
<!-- The example we show here does the following: -->
<!-- - Selects only the `carrier_name` and `arr_delay` from the `flights` dataset and then assigns this subset to a new variable called `flights2`. -->
<!-- - Using `flights2`, we determine the largest arrival delay for each of the carriers. -->
<!-- ```{r max_delays} -->
<!-- flights2 <- flights %>% -->
<!--   select(carrier_name, arr_delay) -->
<!-- max_delays <- flights2 %>% -->
<!--   group_by(carrier_name) %>% -->
<!--   summarize(max_arr_delay = max(arr_delay, na.rm = TRUE)) -->
<!-- ``` -->
<!-- A useful function in the `knitr` package for making nice tables in _R Markdown_ is called `kable`.  It is much easier to use than manually entering values into a table by copying and pasting values into Excel or LaTeX.  This again goes to show how nice reproducible documents can be! (Note the use of `results="asis"`, which will produce the table instead of the code to create the table.)  The `caption.short` argument is used to include a shorter title to appear in the List of Tables. -->
<!-- ```{r maxdelays, results="asis"} -->
<!-- kable(max_delays, -->
<!--       col.names = c("Airline", "Max Arrival Delay"), -->
<!--       caption = "Maximum Delays by Airline", -->
<!--       caption.short = "Max Delays by Airline", -->
<!--       longtable = TRUE, -->
<!--       booktabs = TRUE) -->
<!-- ``` -->
<!-- The last two options make the table a little easier-to-read. -->
<!-- We can further look into the properties of the largest value here for American Airlines Inc.  To do so, we can isolate the row corresponding to the arrival delay of 1539 minutes for American in our original `flights` dataset. -->
<!-- ```{r max_props} -->
<!-- flights %>% filter(arr_delay == 1539, -->
<!--                   carrier_name == "American Airlines Inc.") %>% -->
<!--   select(-c(month, day, carrier, dest_name, hour, -->
<!--             minute, carrier_name, arr_delay)) -->
<!-- ``` -->
<!-- We see that the flight occurred on March 3rd and departed a little after 2 PM on its way to Dallas/Fort Worth.  Lastly, we show how we can visualize the arrival delay of all departing flights from Portland on March 3rd against time of departure. -->
<!-- ```{r march3plot, fig.height=3, fig.width=6} -->
<!-- flights %>% filter(month == 3, day == 3) %>% -->
<!--   ggplot(aes(x = dep_time, y = arr_delay)) + geom_point() -->
<!-- ``` -->
<!-- ## Additional resources -->
<!-- - _Markdown_ Cheatsheet - <https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet> -->
<!-- - _R Markdown_ Reference Guide - <https://www.rstudio.com/wp-content/uploads/2015/03/rmarkdown-reference.pdf> -->
<!-- - Introduction to `dplyr` - <https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html> -->
<!-- - `ggplot2` Documentation - <http://docs.ggplot2.org/current/> -->

</div>
</div>
</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>More can be found on <span class="citation">[10,16,32]</span>.<a href="lt-review.html#fnref1">↩</a></p></li>
<li id="fn2"><p>There is an Arithmetic Brownian Motion: <span class="math inline">\(dS_t = \mu dt + \sigma dB_t\)</span>. More information can be obtained at <span class="citation">[38]</span>.<a href="lt-review.html#fnref2">↩</a></p></li>
<li id="fn3"><p>Also known as exponential Brownian motion.<a href="lt-review.html#fnref3">↩</a></p></li>
<li id="fn4"><p>An intuitive proof can be found at <span class="citation">[27]</span>.<a href="lt-review.html#fnref4">↩</a></p></li>
<li id="fn5"><p>The name derives from the concave shape of the graph, which resembles a smile.<a href="lt-review.html#fnref5">↩</a></p></li>
<li id="fn6"><p>generalized autoregressive conditional heteroscedasticity.<a href="lt-review.html#fnref6">↩</a></p></li>
<li id="fn7"><p>stochastic alpha, beta, rho.<a href="lt-review.html#fnref7">↩</a></p></li>
<li id="fn8"><p>The euler method is the simplest Runge-Kutta method.<a href="lt-review.html#fnref8">↩</a></p></li>
<li id="fn9"><p>Explicit methods calculate the state of a system at a later time from the state of the system at the current time. Mathematically we have something like <span class="math inline">\(Y(t+\Delta t)=F(Y(t))\,\)</span>.<a href="lt-review.html#fnref9">↩</a></p></li>
<li id="fn10"><p>Another possible scheme (not used in this work) is the <em>reflection</em> scheme where we replace <span class="math inline">\(V_t\)</span> with <span class="math inline">\(\mid V_t \mid\)</span><a href="lt-review.html#fnref10">↩</a></p></li>
<li id="fn11"><p>Mathematically: <span class="math inline">\(\mathcal{D} \subseteq \left\{ z \in \mathbb{C} : \mathbb{R} z &lt; 0 \right\}\)</span>.<a href="lt-review.html#fnref11">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="the-heston-model-implementation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"weibo": false,
"instapper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"download": [["thesis.pdf", "PDF"], ["thesis.epub", "EPUB"], ["thesis.docx", "Word"]],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(script.src))
      script.src  = script.src.replace(/^https?:/, '');
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
