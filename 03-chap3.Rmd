```{r include_packages_2, include = FALSE}
# This chunk ensures that the thesisdown package is
# installed and loaded. This thesisdown package includes
# the template files for the thesis and also two functions
# used for labeling and referencing
if(!require(devtools))
  install.packages("devtools", repos = "http://cran.rstudio.com")
if(!require(dplyr))
    install.packages("dplyr", repos = "http://cran.rstudio.com")
if(!require(ggplot2))
    install.packages("ggplot2", repos = "http://cran.rstudio.com")
if(!require(ggplot2))
    install.packages("bookdown", repos = "http://cran.rstudio.com")
if(!require(thesisdown)){
  library(devtools)
  devtools::install_github("ismayc/thesisdown")
  }
library(thesisdown)
```


# Results

We present here the results of all the implementations that were disclosed in the previous section. We perform numerical comparisons between all the methods, setting out differences accross number of simulations and timesteps. 

Heston [-@heston1993closed] gives a closed form used for comparison as the 'true' option value and enabling the results to be exposed in terms of bias ^[Defined as $\mathbb{E} \left[ \hat{\alpha} - \alpha \right]$] and RMSE (root mean square error) ^[Defined as $\sqrt{\mathbb{E}((\hat{\theta}-\theta)^2)}$]. 


The simulaton experiments were performed on a notebook with an Intel(R) Core(TM) i7-4500U CPU @ 1.80GHz processor and 8GB of RAM running on a linux x86_64 based OS, Fedora 25. Codes were all written in R 3.4.1 "Single Candle" [@rlang].

First of all, we chose a parametrization based on what we saw in other works, made some adjustments, like reducing the options' time to maturity due to the slower nature of R language and compared initial the results with the true option price given by the function *callHestoncf* belonging to the package NMOF [@nmofpack]. Parameters can be seen in Table below.




```{r param1, echo=FALSE, message=FALSE, results='asis'}
source("./r_code/parametrization.R")
```


\clearpage

To perform our simulations, we fixed a seed and saved the results in Table \@ref(res). Since the value given by the *callHestoncf* function with the parameters in Table \@ref(param) is 14.176, the method that best approached the "true" value was the modified (drift interpolated) exact algorithm with $100,000$ simulations. Altough the Euler scheme gives the same result (14.16) as the modified EA with $10,000$ simulations, it moves away from the closed form value when we run $100,000$ simulations. 


```{r results1, echo=FALSE, message=FALSE, results='asis'}
source("./r_code/results.R")
```



```{r timmings1, echo=FALSE, message=FALSE, results='asis'}
source("./r_code/timmings.R")
```


Results are observable in Figure \@ref(fig:modcomp1) also. The plot gives a good sense that the Kahl-Jackel has an enormous bias associated with it. In fact, we ran the model ten thousand times, each time ten thousand simulations with different variables set ups and the bias was constantly so big that we discarded the model to subsequent analysis.


```{r modcomp1, echo=FALSE, message=FALSE, results='asis', fig.asp = 0.7, fig.width = 5, fig.align='center', fig.cap='Comparison between models \\label{modcomp1}'}
source("./r_code/mod_comp1.R")
```
